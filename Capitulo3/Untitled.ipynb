{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk,re,pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://gutenberg.org/files/2554/2554-0.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = request.urlopen(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = response.read().decode('utf8')\n",
    "type(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1176967"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ufeffThe Project Gutenberg EBook of Crime and Punishment, by Fyodor Dostoevsky\\r'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw[:75]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separando em palavras e pontuações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = word_tokenize(raw)\n",
    "type(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\ufeffThe',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'EBook',\n",
       " 'of',\n",
       " 'Crime',\n",
       " 'and',\n",
       " 'Punishment',\n",
       " ',',\n",
       " 'by']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = nltk.Text(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.text.Text"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'CHAPTER',\n",
       " 'I',\n",
       " 'On',\n",
       " 'an',\n",
       " 'exceptionally',\n",
       " 'hot',\n",
       " 'evening',\n",
       " 'early',\n",
       " 'in',\n",
       " 'July',\n",
       " 'a',\n",
       " 'young',\n",
       " 'man',\n",
       " 'came',\n",
       " 'out',\n",
       " 'of',\n",
       " 'the',\n",
       " 'garret',\n",
       " 'in',\n",
       " 'which',\n",
       " 'he',\n",
       " 'lodged',\n",
       " 'in',\n",
       " 'S.',\n",
       " 'Place',\n",
       " 'and',\n",
       " 'walked',\n",
       " 'slowly',\n",
       " ',',\n",
       " 'as',\n",
       " 'though',\n",
       " 'in',\n",
       " 'hesitation',\n",
       " ',',\n",
       " 'towards',\n",
       " 'K.',\n",
       " 'bridge']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[1024:1062]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Katerina Ivanovna; Pyotr Petrovitch; Pulcheria Alexandrovna; Avdotya\n",
      "Romanovna; Rodion Romanovitch; Marfa Petrovna; Sofya Semyonovna; old\n",
      "woman; Project Gutenberg-tm; Porfiry Petrovitch; Amalia Ivanovna;\n",
      "great deal; young man; Nikodim Fomitch; Ilya Petrovitch; Project\n",
      "Gutenberg; Andrey Semyonovitch; Hay Market; Dmitri Prokofitch; Good\n",
      "heavens\n"
     ]
    }
   ],
   "source": [
    "text.collocations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5336"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.find(\"PART I\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.rfind(\"End of Project Gutenberg's Crime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = raw[5338:1157743] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195769"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.find(\"PART I\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://news.bbc.co.uk/2/hi/health/2284783.stm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = request.urlopen(url).read().decode('utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!doctype html public \"-//W3C//DTD HTML 4.0 Transitional//EN'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html[:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = BeautifulSoup(html, 'html.parser').get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BBC',\n",
       " 'NEWS',\n",
       " '|',\n",
       " 'Health',\n",
       " '|',\n",
       " 'Blondes',\n",
       " \"'to\",\n",
       " 'die',\n",
       " 'out',\n",
       " 'in',\n",
       " '200',\n",
       " \"years'\",\n",
       " 'NEWS',\n",
       " 'SPORT',\n",
       " 'WEATHER',\n",
       " 'WORLD',\n",
       " 'SERVICE',\n",
       " 'A-Z',\n",
       " 'INDEX',\n",
       " 'SEARCH',\n",
       " 'You',\n",
       " 'are',\n",
       " 'in',\n",
       " ':',\n",
       " 'Health',\n",
       " 'News',\n",
       " 'Front',\n",
       " 'Page',\n",
       " 'Africa',\n",
       " 'Americas',\n",
       " 'Asia-Pacific',\n",
       " 'Europe',\n",
       " 'Middle',\n",
       " 'East',\n",
       " 'South',\n",
       " 'Asia',\n",
       " 'UK',\n",
       " 'Business',\n",
       " 'Entertainment',\n",
       " 'Science/Nature',\n",
       " 'Technology',\n",
       " 'Health',\n",
       " 'Medical',\n",
       " 'notes',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '-',\n",
       " 'Talking',\n",
       " 'Point',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '-',\n",
       " 'Country',\n",
       " 'Profiles',\n",
       " 'In',\n",
       " 'Depth',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '-',\n",
       " 'Programmes',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '-',\n",
       " 'SERVICES',\n",
       " 'Daily',\n",
       " 'E-mail',\n",
       " 'News',\n",
       " 'Ticker',\n",
       " 'Mobile/PDAs',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '-',\n",
       " 'Text',\n",
       " 'Only',\n",
       " 'Feedback',\n",
       " 'Help',\n",
       " 'EDITIONS',\n",
       " 'Change',\n",
       " 'to',\n",
       " 'UK',\n",
       " 'Friday',\n",
       " ',',\n",
       " '27',\n",
       " 'September',\n",
       " ',',\n",
       " '2002',\n",
       " ',',\n",
       " '11:51',\n",
       " 'GMT',\n",
       " '12:51',\n",
       " 'UK',\n",
       " 'Blondes',\n",
       " \"'to\",\n",
       " 'die',\n",
       " 'out',\n",
       " 'in',\n",
       " '200',\n",
       " \"years'\",\n",
       " 'Scientists',\n",
       " 'believe',\n",
       " 'the',\n",
       " 'last',\n",
       " 'blondes',\n",
       " 'will',\n",
       " 'be',\n",
       " 'in',\n",
       " 'Finland',\n",
       " 'The',\n",
       " 'last',\n",
       " 'natural',\n",
       " 'blondes',\n",
       " 'will',\n",
       " 'die',\n",
       " 'out',\n",
       " 'within',\n",
       " '200',\n",
       " 'years',\n",
       " ',',\n",
       " 'scientists',\n",
       " 'believe',\n",
       " '.',\n",
       " 'A',\n",
       " 'study',\n",
       " 'by',\n",
       " 'experts',\n",
       " 'in',\n",
       " 'Germany',\n",
       " 'suggests',\n",
       " 'people',\n",
       " 'with',\n",
       " 'blonde',\n",
       " 'hair',\n",
       " 'are',\n",
       " 'an',\n",
       " 'endangered',\n",
       " 'species',\n",
       " 'and',\n",
       " 'will',\n",
       " 'become',\n",
       " 'extinct',\n",
       " 'by',\n",
       " '2202',\n",
       " '.',\n",
       " 'Researchers',\n",
       " 'predict',\n",
       " 'the',\n",
       " 'last',\n",
       " 'truly',\n",
       " 'natural',\n",
       " 'blonde',\n",
       " 'will',\n",
       " 'be',\n",
       " 'born',\n",
       " 'in',\n",
       " 'Finland',\n",
       " '-',\n",
       " 'the',\n",
       " 'country',\n",
       " 'with',\n",
       " 'the',\n",
       " 'highest',\n",
       " 'proportion',\n",
       " 'of',\n",
       " 'blondes',\n",
       " '.',\n",
       " 'The',\n",
       " 'frequency',\n",
       " 'of',\n",
       " 'blondes',\n",
       " 'may',\n",
       " 'drop',\n",
       " 'but',\n",
       " 'they',\n",
       " 'wo',\n",
       " \"n't\",\n",
       " 'disappear',\n",
       " 'Prof',\n",
       " 'Jonathan',\n",
       " 'Rees',\n",
       " ',',\n",
       " 'University',\n",
       " 'of',\n",
       " 'Edinburgh',\n",
       " 'But',\n",
       " 'they',\n",
       " 'say',\n",
       " 'too',\n",
       " 'few',\n",
       " 'people',\n",
       " 'now',\n",
       " 'carry',\n",
       " 'the',\n",
       " 'gene',\n",
       " 'for',\n",
       " 'blondes',\n",
       " 'to',\n",
       " 'last',\n",
       " 'beyond',\n",
       " 'the',\n",
       " 'next',\n",
       " 'two',\n",
       " 'centuries',\n",
       " '.',\n",
       " 'The',\n",
       " 'problem',\n",
       " 'is',\n",
       " 'that',\n",
       " 'blonde',\n",
       " 'hair',\n",
       " 'is',\n",
       " 'caused',\n",
       " 'by',\n",
       " 'a',\n",
       " 'recessive',\n",
       " 'gene',\n",
       " '.',\n",
       " 'In',\n",
       " 'order',\n",
       " 'for',\n",
       " 'a',\n",
       " 'child',\n",
       " 'to',\n",
       " 'have',\n",
       " 'blonde',\n",
       " 'hair',\n",
       " ',',\n",
       " 'it',\n",
       " 'must',\n",
       " 'have',\n",
       " 'the',\n",
       " 'gene',\n",
       " 'on',\n",
       " 'both',\n",
       " 'sides',\n",
       " 'of',\n",
       " 'the',\n",
       " 'family',\n",
       " 'in',\n",
       " 'the',\n",
       " 'grandparents',\n",
       " \"'\",\n",
       " 'generation',\n",
       " '.',\n",
       " 'Dyed',\n",
       " 'rivals',\n",
       " 'The',\n",
       " 'researchers',\n",
       " 'also',\n",
       " 'believe',\n",
       " 'that',\n",
       " 'so-called',\n",
       " 'bottle',\n",
       " 'blondes',\n",
       " 'may',\n",
       " 'be',\n",
       " 'to',\n",
       " 'blame',\n",
       " 'for',\n",
       " 'the',\n",
       " 'demise',\n",
       " 'of',\n",
       " 'their',\n",
       " 'natural',\n",
       " 'rivals',\n",
       " '.',\n",
       " 'They',\n",
       " 'suggest',\n",
       " 'that',\n",
       " 'dyed-blondes',\n",
       " 'are',\n",
       " 'more',\n",
       " 'attractive',\n",
       " 'to',\n",
       " 'men',\n",
       " 'who',\n",
       " 'choose',\n",
       " 'them',\n",
       " 'as',\n",
       " 'partners',\n",
       " 'over',\n",
       " 'true',\n",
       " 'blondes',\n",
       " '.',\n",
       " 'Bottle-blondes',\n",
       " 'like',\n",
       " 'Ann',\n",
       " 'Widdecombe',\n",
       " 'may',\n",
       " 'be',\n",
       " 'to',\n",
       " 'blame',\n",
       " 'But',\n",
       " 'Jonathan',\n",
       " 'Rees',\n",
       " ',',\n",
       " 'professor',\n",
       " 'of',\n",
       " 'dermatology',\n",
       " 'at',\n",
       " 'the',\n",
       " 'University',\n",
       " 'of',\n",
       " 'Edinburgh',\n",
       " 'said',\n",
       " 'it',\n",
       " 'was',\n",
       " 'unlikely',\n",
       " 'blondes',\n",
       " 'would',\n",
       " 'die',\n",
       " 'out',\n",
       " 'completely',\n",
       " '.',\n",
       " '``',\n",
       " 'Genes',\n",
       " 'do',\n",
       " \"n't\",\n",
       " 'die',\n",
       " 'out',\n",
       " 'unless',\n",
       " 'there',\n",
       " 'is',\n",
       " 'a',\n",
       " 'disadvantage',\n",
       " 'of',\n",
       " 'having',\n",
       " 'that',\n",
       " 'gene',\n",
       " 'or',\n",
       " 'by',\n",
       " 'chance',\n",
       " '.',\n",
       " 'They',\n",
       " 'do',\n",
       " \"n't\",\n",
       " 'disappear',\n",
       " ',',\n",
       " \"''\",\n",
       " 'he',\n",
       " 'told',\n",
       " 'BBC',\n",
       " 'News',\n",
       " 'Online',\n",
       " '.',\n",
       " '``',\n",
       " 'The',\n",
       " 'only',\n",
       " 'reason',\n",
       " 'blondes',\n",
       " 'would',\n",
       " 'disappear',\n",
       " 'is',\n",
       " 'if',\n",
       " 'having',\n",
       " 'the',\n",
       " 'gene',\n",
       " 'was',\n",
       " 'a',\n",
       " 'disadvantage',\n",
       " 'and',\n",
       " 'I',\n",
       " 'do',\n",
       " 'not',\n",
       " 'think',\n",
       " 'that',\n",
       " 'is',\n",
       " 'the',\n",
       " 'case',\n",
       " '.',\n",
       " '``',\n",
       " 'The',\n",
       " 'frequency',\n",
       " 'of',\n",
       " 'blondes',\n",
       " 'may',\n",
       " 'drop',\n",
       " 'but',\n",
       " 'they',\n",
       " 'wo',\n",
       " \"n't\",\n",
       " 'disappear',\n",
       " '.',\n",
       " \"''\",\n",
       " 'See',\n",
       " 'also',\n",
       " ':',\n",
       " '28',\n",
       " 'Mar',\n",
       " '01',\n",
       " '|',\n",
       " 'Education',\n",
       " 'What',\n",
       " 'is',\n",
       " 'it',\n",
       " 'about',\n",
       " 'blondes',\n",
       " '?',\n",
       " '09',\n",
       " 'Apr',\n",
       " '99',\n",
       " '|',\n",
       " 'Health',\n",
       " 'Platinum',\n",
       " 'blondes',\n",
       " 'are',\n",
       " 'labelled',\n",
       " 'as',\n",
       " 'dumb',\n",
       " '17',\n",
       " 'Apr',\n",
       " '02',\n",
       " '|',\n",
       " 'Health',\n",
       " 'Hair',\n",
       " 'dye',\n",
       " 'cancer',\n",
       " 'alert',\n",
       " 'Internet',\n",
       " 'links',\n",
       " ':',\n",
       " 'University',\n",
       " 'of',\n",
       " 'Edinburgh',\n",
       " 'The',\n",
       " 'BBC',\n",
       " 'is',\n",
       " 'not',\n",
       " 'responsible',\n",
       " 'for',\n",
       " 'the',\n",
       " 'content',\n",
       " 'of',\n",
       " 'external',\n",
       " 'internet',\n",
       " 'sites',\n",
       " 'Top',\n",
       " 'Health',\n",
       " 'stories',\n",
       " 'now',\n",
       " ':',\n",
       " 'Heart',\n",
       " 'risk',\n",
       " 'link',\n",
       " 'to',\n",
       " 'big',\n",
       " 'families',\n",
       " 'Back',\n",
       " 'pain',\n",
       " 'drug',\n",
       " \"'may\",\n",
       " 'aid',\n",
       " \"diabetics'\",\n",
       " 'Congo',\n",
       " 'Ebola',\n",
       " 'outbreak',\n",
       " 'confirmed',\n",
       " 'Vegetables',\n",
       " 'ward',\n",
       " 'off',\n",
       " \"Alzheimer's\",\n",
       " 'Polio',\n",
       " 'campaign',\n",
       " 'launched',\n",
       " 'in',\n",
       " 'Iraq',\n",
       " 'Gene',\n",
       " 'defect',\n",
       " 'explains',\n",
       " 'high',\n",
       " 'blood',\n",
       " 'pressure',\n",
       " 'Botox',\n",
       " \"'may\",\n",
       " 'cause',\n",
       " 'new',\n",
       " \"wrinkles'\",\n",
       " 'Alien',\n",
       " \"'abductees\",\n",
       " \"'\",\n",
       " 'show',\n",
       " 'real',\n",
       " 'symptoms',\n",
       " 'Links',\n",
       " 'to',\n",
       " 'more',\n",
       " 'Health',\n",
       " 'stories',\n",
       " 'are',\n",
       " 'at',\n",
       " 'the',\n",
       " 'foot',\n",
       " 'of',\n",
       " 'the',\n",
       " 'page',\n",
       " '.',\n",
       " 'E-mail',\n",
       " 'this',\n",
       " 'story',\n",
       " 'to',\n",
       " 'a',\n",
       " 'friend',\n",
       " 'Links',\n",
       " 'to',\n",
       " 'more',\n",
       " 'Health',\n",
       " 'stories',\n",
       " 'In',\n",
       " 'This',\n",
       " 'Section',\n",
       " 'Heart',\n",
       " 'risk',\n",
       " 'link',\n",
       " 'to',\n",
       " 'big',\n",
       " 'families',\n",
       " 'Back',\n",
       " 'pain',\n",
       " 'drug',\n",
       " \"'may\",\n",
       " 'aid',\n",
       " \"diabetics'\",\n",
       " 'Congo',\n",
       " 'Ebola',\n",
       " 'outbreak',\n",
       " 'confirmed',\n",
       " 'Vegetables',\n",
       " 'ward',\n",
       " 'off',\n",
       " \"Alzheimer's\",\n",
       " 'Polio',\n",
       " 'campaign',\n",
       " 'launched',\n",
       " 'in',\n",
       " 'Iraq',\n",
       " 'Gene',\n",
       " 'defect',\n",
       " 'explains',\n",
       " 'high',\n",
       " 'blood',\n",
       " 'pressure',\n",
       " 'Botox',\n",
       " \"'may\",\n",
       " 'cause',\n",
       " 'new',\n",
       " \"wrinkles'\",\n",
       " 'Alien',\n",
       " \"'abductees\",\n",
       " \"'\",\n",
       " 'show',\n",
       " 'real',\n",
       " 'symptoms',\n",
       " 'How',\n",
       " 'sperm',\n",
       " 'wriggle',\n",
       " 'Bollywood',\n",
       " 'told',\n",
       " 'to',\n",
       " 'stub',\n",
       " 'it',\n",
       " 'out',\n",
       " 'Fears',\n",
       " 'over',\n",
       " 'tuna',\n",
       " 'health',\n",
       " 'risk',\n",
       " 'to',\n",
       " 'babies',\n",
       " 'Public',\n",
       " 'can',\n",
       " 'be',\n",
       " 'taught',\n",
       " 'to',\n",
       " 'spot',\n",
       " 'strokes',\n",
       " '^^',\n",
       " 'Back',\n",
       " 'to',\n",
       " 'top',\n",
       " 'News',\n",
       " 'Front',\n",
       " 'Page',\n",
       " '|',\n",
       " 'Africa',\n",
       " '|',\n",
       " 'Americas',\n",
       " '|',\n",
       " 'Asia-Pacific',\n",
       " '|',\n",
       " 'Europe',\n",
       " '|',\n",
       " 'Middle',\n",
       " 'East',\n",
       " '|',\n",
       " 'South',\n",
       " 'Asia',\n",
       " '|',\n",
       " 'UK',\n",
       " '|',\n",
       " 'Business',\n",
       " '|',\n",
       " 'Entertainment',\n",
       " '|',\n",
       " 'Science/Nature',\n",
       " '|',\n",
       " 'Technology',\n",
       " '|',\n",
       " 'Health',\n",
       " '|',\n",
       " 'Talking',\n",
       " 'Point',\n",
       " '|',\n",
       " 'Country',\n",
       " 'Profiles',\n",
       " '|',\n",
       " 'In',\n",
       " 'Depth',\n",
       " '|',\n",
       " 'Programmes',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " 'To',\n",
       " 'BBC',\n",
       " 'Sport',\n",
       " '>',\n",
       " '>',\n",
       " '|',\n",
       " 'To',\n",
       " 'BBC',\n",
       " 'Weather',\n",
       " '>',\n",
       " '>',\n",
       " '|',\n",
       " 'To',\n",
       " 'BBC',\n",
       " 'World',\n",
       " 'Service',\n",
       " '>',\n",
       " '>',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '©',\n",
       " 'MMIII',\n",
       " '|',\n",
       " 'News',\n",
       " 'Sources',\n",
       " '|',\n",
       " 'Privacy']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = word_tokenize(raw)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 5 of 5 matches:\n",
      "hey say too few people now carry the gene for blondes to last beyond the next \n",
      "blonde hair is caused by a recessive gene . In order for a child to have blond\n",
      " have blonde hair , it must have the gene on both sides of the family in the g\n",
      "ere is a disadvantage of having that gene or by chance . They do n't disappear\n",
      "des would disappear is if having the gene was a disadvantage and I do not thin\n"
     ]
    }
   ],
   "source": [
    "tokens = tokens[110:390]\n",
    "text = nltk.Text(tokens)\n",
    "text.concordance('gene')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser\n",
    "llog = feedparser.parse(\"http://languagelog.ldc.upenn.edu/nll/?feed=atom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Language Log'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llog['feed']['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(llog.entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Metonymy of the week'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post = llog.entries[2]\n",
    "post.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<p>Lawrence Downes, \"<a href=\"https://www.washingtonpost.com/outlook/s'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content = post.content[0].value\n",
    "content[:70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lawrence',\n",
       " 'Downes',\n",
       " ',',\n",
       " '``',\n",
       " 'How',\n",
       " 'to',\n",
       " 'turn',\n",
       " 'Sean',\n",
       " 'Hannity',\n",
       " 'into',\n",
       " 'food',\n",
       " 'for',\n",
       " 'worms',\n",
       " \"''\",\n",
       " ',',\n",
       " 'WaPo',\n",
       " '8/6/2020',\n",
       " ':',\n",
       " 'I',\n",
       " 'didn',\n",
       " '’',\n",
       " 't',\n",
       " 'set',\n",
       " 'out',\n",
       " 'to',\n",
       " 'compost',\n",
       " 'Sean',\n",
       " 'Hannity',\n",
       " '.',\n",
       " 'It',\n",
       " 'was',\n",
       " 'something',\n",
       " 'I',\n",
       " 'settled',\n",
       " 'on',\n",
       " 'after',\n",
       " 'considering',\n",
       " 'several',\n",
       " 'other',\n",
       " 'options',\n",
       " 'and',\n",
       " 'rejecting',\n",
       " 'them',\n",
       " 'one',\n",
       " 'by',\n",
       " 'one',\n",
       " '.',\n",
       " 'The',\n",
       " 'first',\n",
       " 'was',\n",
       " 'leaving',\n",
       " 'him',\n",
       " 'in',\n",
       " 'the',\n",
       " 'basement',\n",
       " 'indefinitely',\n",
       " '.',\n",
       " 'That',\n",
       " 'worked',\n",
       " 'for',\n",
       " 'a',\n",
       " 'while',\n",
       " '.',\n",
       " 'I',\n",
       " 'could',\n",
       " 'almost',\n",
       " 'forget',\n",
       " 'about',\n",
       " 'him',\n",
       " 'there',\n",
       " ',',\n",
       " 'but',\n",
       " 'then',\n",
       " 'I',\n",
       " 'would',\n",
       " 'go',\n",
       " 'down',\n",
       " 'with',\n",
       " 'a',\n",
       " 'basket',\n",
       " 'of',\n",
       " 'laundry',\n",
       " 'and',\n",
       " 'see',\n",
       " 'him',\n",
       " 'and',\n",
       " 'think',\n",
       " ',',\n",
       " 'I',\n",
       " 'have',\n",
       " 'to',\n",
       " 'do',\n",
       " 'something',\n",
       " '.',\n",
       " 'I',\n",
       " 'should',\n",
       " 'explain',\n",
       " ':',\n",
       " 'I',\n",
       " 'don',\n",
       " '’',\n",
       " 't',\n",
       " 'mean',\n",
       " 'the',\n",
       " 'man',\n",
       " 'himself',\n",
       " ',',\n",
       " 'but',\n",
       " 'Hannity',\n",
       " 'the',\n",
       " 'book',\n",
       " '.',\n",
       " 'It',\n",
       " '’',\n",
       " 's',\n",
       " 'called',\n",
       " '“',\n",
       " 'Let',\n",
       " 'Freedom',\n",
       " 'Ring',\n",
       " ':',\n",
       " 'Winning',\n",
       " 'the',\n",
       " 'War',\n",
       " 'of',\n",
       " 'Liberty',\n",
       " 'Over',\n",
       " 'Liberalism.',\n",
       " '”',\n",
       " 'The',\n",
       " 'article',\n",
       " \"'s\",\n",
       " 'subhead',\n",
       " 'gives',\n",
       " 'the',\n",
       " 'game',\n",
       " 'away',\n",
       " ':',\n",
       " '``',\n",
       " 'Rancid',\n",
       " 'words',\n",
       " 'can',\n",
       " 'make',\n",
       " 'excellent',\n",
       " 'radishes',\n",
       " '.',\n",
       " 'Just',\n",
       " 'shred',\n",
       " 'and',\n",
       " 'compost',\n",
       " '.',\n",
       " \"''\",\n",
       " 'Also',\n",
       " 'the',\n",
       " 'image',\n",
       " ':',\n",
       " 'The',\n",
       " 'OED',\n",
       " 'glosses',\n",
       " 'metonymy',\n",
       " 'as',\n",
       " '(',\n",
       " 'A',\n",
       " 'figure',\n",
       " 'of',\n",
       " 'speech',\n",
       " 'characterized',\n",
       " 'by',\n",
       " ')',\n",
       " 'the',\n",
       " 'action',\n",
       " 'of',\n",
       " 'substituting',\n",
       " 'for',\n",
       " 'a',\n",
       " 'word',\n",
       " 'or',\n",
       " 'phrase',\n",
       " 'denoting',\n",
       " 'an',\n",
       " 'object',\n",
       " ',',\n",
       " 'action',\n",
       " ',',\n",
       " 'institution',\n",
       " ',',\n",
       " 'etc.',\n",
       " ',',\n",
       " 'a',\n",
       " 'word',\n",
       " 'or',\n",
       " 'phrase',\n",
       " 'denoting',\n",
       " 'a',\n",
       " 'property',\n",
       " 'or',\n",
       " 'something',\n",
       " 'associated',\n",
       " 'with',\n",
       " 'it',\n",
       " ',',\n",
       " 'e.g',\n",
       " '.',\n",
       " 'as',\n",
       " 'when',\n",
       " 'referring',\n",
       " 'to',\n",
       " 'the',\n",
       " 'monarchy',\n",
       " 'as',\n",
       " '‘',\n",
       " 'the',\n",
       " 'crown',\n",
       " '’',\n",
       " 'or',\n",
       " 'the',\n",
       " 'theatre',\n",
       " 'as',\n",
       " '‘',\n",
       " 'the',\n",
       " 'stage',\n",
       " '’',\n",
       " ';',\n",
       " 'an',\n",
       " 'instance',\n",
       " 'of',\n",
       " 'this',\n",
       " '.',\n",
       " '(',\n",
       " 'b',\n",
       " ')',\n",
       " 'In',\n",
       " 'extended',\n",
       " 'use',\n",
       " ':',\n",
       " 'a',\n",
       " 'thing',\n",
       " 'used',\n",
       " 'or',\n",
       " 'regarded',\n",
       " 'as',\n",
       " 'a',\n",
       " 'substitute',\n",
       " 'for',\n",
       " 'or',\n",
       " 'symbol',\n",
       " 'of',\n",
       " 'something',\n",
       " 'else',\n",
       " '.',\n",
       " 'Also',\n",
       " '(',\n",
       " 'esp',\n",
       " '.',\n",
       " 'in',\n",
       " 'Linguistics',\n",
       " 'and',\n",
       " 'Literary',\n",
       " 'Theory',\n",
       " ')',\n",
       " ':',\n",
       " 'the',\n",
       " 'process',\n",
       " 'of',\n",
       " 'semantic',\n",
       " 'association',\n",
       " 'involved',\n",
       " 'in',\n",
       " 'producing',\n",
       " 'and',\n",
       " 'understanding',\n",
       " 'a',\n",
       " 'metonymy',\n",
       " '.',\n",
       " 'More',\n",
       " 'succinctly',\n",
       " ',',\n",
       " 'Wikipedia',\n",
       " 'says',\n",
       " 'that',\n",
       " 'metonymy',\n",
       " 'is',\n",
       " '``',\n",
       " 'a',\n",
       " 'figure',\n",
       " 'of',\n",
       " 'speech',\n",
       " 'in',\n",
       " 'which',\n",
       " 'a',\n",
       " 'thing',\n",
       " 'or',\n",
       " 'concept',\n",
       " 'is',\n",
       " 'referred',\n",
       " 'to',\n",
       " 'by',\n",
       " 'the',\n",
       " 'name',\n",
       " 'of',\n",
       " 'something',\n",
       " 'closely',\n",
       " 'associated',\n",
       " 'with',\n",
       " 'that',\n",
       " 'thing',\n",
       " 'or',\n",
       " 'concept',\n",
       " '.',\n",
       " \"''\",\n",
       " 'So',\n",
       " 'in',\n",
       " 'this',\n",
       " 'case',\n",
       " ',',\n",
       " '``',\n",
       " 'Sean',\n",
       " 'Hannity',\n",
       " \"''\",\n",
       " 'is',\n",
       " 'used',\n",
       " 'to',\n",
       " 'refer',\n",
       " 'to',\n",
       " 'his',\n",
       " 'books',\n",
       " 'as',\n",
       " 'physical',\n",
       " 'objects',\n",
       " ',',\n",
       " 'just',\n",
       " 'as',\n",
       " '``',\n",
       " 'The',\n",
       " 'White',\n",
       " 'House',\n",
       " \"''\",\n",
       " 'can',\n",
       " 'be',\n",
       " 'used',\n",
       " 'to',\n",
       " 'refer',\n",
       " 'to',\n",
       " 'the',\n",
       " 'current',\n",
       " 'U.S.',\n",
       " 'executive',\n",
       " 'branch',\n",
       " ',',\n",
       " 'and',\n",
       " '``',\n",
       " 'The',\n",
       " 'Washington',\n",
       " 'Post',\n",
       " \"''\",\n",
       " 'can',\n",
       " 'be',\n",
       " 'used',\n",
       " 'to',\n",
       " 'refer',\n",
       " 'to',\n",
       " '(',\n",
       " 'an',\n",
       " 'instance',\n",
       " 'of',\n",
       " ')',\n",
       " 'the',\n",
       " 'printed',\n",
       " 'newspaper',\n",
       " '.',\n",
       " 'Apparently',\n",
       " 'it',\n",
       " \"'s\",\n",
       " 'safe',\n",
       " 'and',\n",
       " 'effective',\n",
       " 'to',\n",
       " 'compost',\n",
       " 'newspapers',\n",
       " 'as',\n",
       " 'well',\n",
       " 'as',\n",
       " 'books',\n",
       " ',',\n",
       " 'whether',\n",
       " 'or',\n",
       " 'not',\n",
       " 'you',\n",
       " 'approve',\n",
       " 'of',\n",
       " 'the',\n",
       " 'editorial',\n",
       " 'content',\n",
       " '.',\n",
       " 'Of',\n",
       " 'course',\n",
       " ',',\n",
       " 'composting',\n",
       " 'is',\n",
       " 'a',\n",
       " 'sort',\n",
       " 'of',\n",
       " 'slow',\n",
       " 'microbially-aided',\n",
       " 'burn',\n",
       " ',',\n",
       " 'though',\n",
       " 'clearly',\n",
       " 'some',\n",
       " 'people',\n",
       " 'who',\n",
       " 'would',\n",
       " 'be',\n",
       " 'reluctant',\n",
       " 'to',\n",
       " 'burn',\n",
       " 'books',\n",
       " 'or',\n",
       " 'newspapers',\n",
       " 'are',\n",
       " 'happy',\n",
       " 'to',\n",
       " 'compost',\n",
       " 'them',\n",
       " '.']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = BeautifulSoup(content, 'html.parser').get_text()\n",
    "word_tokenize(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Language Log'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import feedparser\n",
    "llog = feedparser.parse(\"http://languagelog.ldc.upenn.edu/nll/?feed=atom\")\n",
    "llog['feed']['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(llog.entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Metonymy of the week'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post = llog.entries[2]\n",
    "post.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<p>Lawrence Downes, \"<a href=\"https://www.washingtonpost.com/outlook/s'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content = post.content[0].value\n",
    "content[:70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lawrence',\n",
       " 'Downes',\n",
       " ',',\n",
       " '``',\n",
       " 'How',\n",
       " 'to',\n",
       " 'turn',\n",
       " 'Sean',\n",
       " 'Hannity',\n",
       " 'into',\n",
       " 'food',\n",
       " 'for',\n",
       " 'worms',\n",
       " \"''\",\n",
       " ',',\n",
       " 'WaPo',\n",
       " '8/6/2020',\n",
       " ':',\n",
       " 'I',\n",
       " 'didn',\n",
       " '’',\n",
       " 't',\n",
       " 'set',\n",
       " 'out',\n",
       " 'to',\n",
       " 'compost',\n",
       " 'Sean',\n",
       " 'Hannity',\n",
       " '.',\n",
       " 'It',\n",
       " 'was',\n",
       " 'something',\n",
       " 'I',\n",
       " 'settled',\n",
       " 'on',\n",
       " 'after',\n",
       " 'considering',\n",
       " 'several',\n",
       " 'other',\n",
       " 'options',\n",
       " 'and',\n",
       " 'rejecting',\n",
       " 'them',\n",
       " 'one',\n",
       " 'by',\n",
       " 'one',\n",
       " '.',\n",
       " 'The',\n",
       " 'first',\n",
       " 'was',\n",
       " 'leaving',\n",
       " 'him',\n",
       " 'in',\n",
       " 'the',\n",
       " 'basement',\n",
       " 'indefinitely',\n",
       " '.',\n",
       " 'That',\n",
       " 'worked',\n",
       " 'for',\n",
       " 'a',\n",
       " 'while',\n",
       " '.',\n",
       " 'I',\n",
       " 'could',\n",
       " 'almost',\n",
       " 'forget',\n",
       " 'about',\n",
       " 'him',\n",
       " 'there',\n",
       " ',',\n",
       " 'but',\n",
       " 'then',\n",
       " 'I',\n",
       " 'would',\n",
       " 'go',\n",
       " 'down',\n",
       " 'with',\n",
       " 'a',\n",
       " 'basket',\n",
       " 'of',\n",
       " 'laundry',\n",
       " 'and',\n",
       " 'see',\n",
       " 'him',\n",
       " 'and',\n",
       " 'think',\n",
       " ',',\n",
       " 'I',\n",
       " 'have',\n",
       " 'to',\n",
       " 'do',\n",
       " 'something',\n",
       " '.',\n",
       " 'I',\n",
       " 'should',\n",
       " 'explain',\n",
       " ':',\n",
       " 'I',\n",
       " 'don',\n",
       " '’',\n",
       " 't',\n",
       " 'mean',\n",
       " 'the',\n",
       " 'man',\n",
       " 'himself',\n",
       " ',',\n",
       " 'but',\n",
       " 'Hannity',\n",
       " 'the',\n",
       " 'book',\n",
       " '.',\n",
       " 'It',\n",
       " '’',\n",
       " 's',\n",
       " 'called',\n",
       " '“',\n",
       " 'Let',\n",
       " 'Freedom',\n",
       " 'Ring',\n",
       " ':',\n",
       " 'Winning',\n",
       " 'the',\n",
       " 'War',\n",
       " 'of',\n",
       " 'Liberty',\n",
       " 'Over',\n",
       " 'Liberalism.',\n",
       " '”',\n",
       " 'The',\n",
       " 'article',\n",
       " \"'s\",\n",
       " 'subhead',\n",
       " 'gives',\n",
       " 'the',\n",
       " 'game',\n",
       " 'away',\n",
       " ':',\n",
       " '``',\n",
       " 'Rancid',\n",
       " 'words',\n",
       " 'can',\n",
       " 'make',\n",
       " 'excellent',\n",
       " 'radishes',\n",
       " '.',\n",
       " 'Just',\n",
       " 'shred',\n",
       " 'and',\n",
       " 'compost',\n",
       " '.',\n",
       " \"''\",\n",
       " 'Also',\n",
       " 'the',\n",
       " 'image',\n",
       " ':',\n",
       " 'The',\n",
       " 'OED',\n",
       " 'glosses',\n",
       " 'metonymy',\n",
       " 'as',\n",
       " '(',\n",
       " 'A',\n",
       " 'figure',\n",
       " 'of',\n",
       " 'speech',\n",
       " 'characterized',\n",
       " 'by',\n",
       " ')',\n",
       " 'the',\n",
       " 'action',\n",
       " 'of',\n",
       " 'substituting',\n",
       " 'for',\n",
       " 'a',\n",
       " 'word',\n",
       " 'or',\n",
       " 'phrase',\n",
       " 'denoting',\n",
       " 'an',\n",
       " 'object',\n",
       " ',',\n",
       " 'action',\n",
       " ',',\n",
       " 'institution',\n",
       " ',',\n",
       " 'etc.',\n",
       " ',',\n",
       " 'a',\n",
       " 'word',\n",
       " 'or',\n",
       " 'phrase',\n",
       " 'denoting',\n",
       " 'a',\n",
       " 'property',\n",
       " 'or',\n",
       " 'something',\n",
       " 'associated',\n",
       " 'with',\n",
       " 'it',\n",
       " ',',\n",
       " 'e.g',\n",
       " '.',\n",
       " 'as',\n",
       " 'when',\n",
       " 'referring',\n",
       " 'to',\n",
       " 'the',\n",
       " 'monarchy',\n",
       " 'as',\n",
       " '‘',\n",
       " 'the',\n",
       " 'crown',\n",
       " '’',\n",
       " 'or',\n",
       " 'the',\n",
       " 'theatre',\n",
       " 'as',\n",
       " '‘',\n",
       " 'the',\n",
       " 'stage',\n",
       " '’',\n",
       " ';',\n",
       " 'an',\n",
       " 'instance',\n",
       " 'of',\n",
       " 'this',\n",
       " '.',\n",
       " '(',\n",
       " 'b',\n",
       " ')',\n",
       " 'In',\n",
       " 'extended',\n",
       " 'use',\n",
       " ':',\n",
       " 'a',\n",
       " 'thing',\n",
       " 'used',\n",
       " 'or',\n",
       " 'regarded',\n",
       " 'as',\n",
       " 'a',\n",
       " 'substitute',\n",
       " 'for',\n",
       " 'or',\n",
       " 'symbol',\n",
       " 'of',\n",
       " 'something',\n",
       " 'else',\n",
       " '.',\n",
       " 'Also',\n",
       " '(',\n",
       " 'esp',\n",
       " '.',\n",
       " 'in',\n",
       " 'Linguistics',\n",
       " 'and',\n",
       " 'Literary',\n",
       " 'Theory',\n",
       " ')',\n",
       " ':',\n",
       " 'the',\n",
       " 'process',\n",
       " 'of',\n",
       " 'semantic',\n",
       " 'association',\n",
       " 'involved',\n",
       " 'in',\n",
       " 'producing',\n",
       " 'and',\n",
       " 'understanding',\n",
       " 'a',\n",
       " 'metonymy',\n",
       " '.',\n",
       " 'More',\n",
       " 'succinctly',\n",
       " ',',\n",
       " 'Wikipedia',\n",
       " 'says',\n",
       " 'that',\n",
       " 'metonymy',\n",
       " 'is',\n",
       " '``',\n",
       " 'a',\n",
       " 'figure',\n",
       " 'of',\n",
       " 'speech',\n",
       " 'in',\n",
       " 'which',\n",
       " 'a',\n",
       " 'thing',\n",
       " 'or',\n",
       " 'concept',\n",
       " 'is',\n",
       " 'referred',\n",
       " 'to',\n",
       " 'by',\n",
       " 'the',\n",
       " 'name',\n",
       " 'of',\n",
       " 'something',\n",
       " 'closely',\n",
       " 'associated',\n",
       " 'with',\n",
       " 'that',\n",
       " 'thing',\n",
       " 'or',\n",
       " 'concept',\n",
       " '.',\n",
       " \"''\",\n",
       " 'So',\n",
       " 'in',\n",
       " 'this',\n",
       " 'case',\n",
       " ',',\n",
       " '``',\n",
       " 'Sean',\n",
       " 'Hannity',\n",
       " \"''\",\n",
       " 'is',\n",
       " 'used',\n",
       " 'to',\n",
       " 'refer',\n",
       " 'to',\n",
       " 'his',\n",
       " 'books',\n",
       " 'as',\n",
       " 'physical',\n",
       " 'objects',\n",
       " ',',\n",
       " 'just',\n",
       " 'as',\n",
       " '``',\n",
       " 'The',\n",
       " 'White',\n",
       " 'House',\n",
       " \"''\",\n",
       " 'can',\n",
       " 'be',\n",
       " 'used',\n",
       " 'to',\n",
       " 'refer',\n",
       " 'to',\n",
       " 'the',\n",
       " 'current',\n",
       " 'U.S.',\n",
       " 'executive',\n",
       " 'branch',\n",
       " ',',\n",
       " 'and',\n",
       " '``',\n",
       " 'The',\n",
       " 'Washington',\n",
       " 'Post',\n",
       " \"''\",\n",
       " 'can',\n",
       " 'be',\n",
       " 'used',\n",
       " 'to',\n",
       " 'refer',\n",
       " 'to',\n",
       " '(',\n",
       " 'an',\n",
       " 'instance',\n",
       " 'of',\n",
       " ')',\n",
       " 'the',\n",
       " 'printed',\n",
       " 'newspaper',\n",
       " '.',\n",
       " 'Apparently',\n",
       " 'it',\n",
       " \"'s\",\n",
       " 'safe',\n",
       " 'and',\n",
       " 'effective',\n",
       " 'to',\n",
       " 'compost',\n",
       " 'newspapers',\n",
       " 'as',\n",
       " 'well',\n",
       " 'as',\n",
       " 'books',\n",
       " ',',\n",
       " 'whether',\n",
       " 'or',\n",
       " 'not',\n",
       " 'you',\n",
       " 'approve',\n",
       " 'of',\n",
       " 'the',\n",
       " 'editorial',\n",
       " 'content',\n",
       " '.',\n",
       " 'Of',\n",
       " 'course',\n",
       " ',',\n",
       " 'composting',\n",
       " 'is',\n",
       " 'a',\n",
       " 'sort',\n",
       " 'of',\n",
       " 'slow',\n",
       " 'microbially-aided',\n",
       " 'burn',\n",
       " ',',\n",
       " 'though',\n",
       " 'clearly',\n",
       " 'some',\n",
       " 'people',\n",
       " 'who',\n",
       " 'would',\n",
       " 'be',\n",
       " 'reluctant',\n",
       " 'to',\n",
       " 'burn',\n",
       " 'books',\n",
       " 'or',\n",
       " 'newspapers',\n",
       " 'are',\n",
       " 'happy',\n",
       " 'to',\n",
       " 'compost',\n",
       " 'them',\n",
       " '.']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = BeautifulSoup(content, 'html.parser').get_text()\n",
    "word_tokenize(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f = open ( 'document.txt' )\n",
    "#raw = f.read ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints', 'Untitled.ipynb']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir ( '.' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 'r' significa abrir o arquivo para leitura (o padrão), e ' U ' significa \"Universal\", o que nos permite ignorar as diferentes convenções usadas para marcar novas linhas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " método read () cria uma string com o conteúdo de todo o arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f.read()\n",
    "#f = open ( 'document.txt' , 'rU' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for line in f:\n",
    " #   print(line.strip())\n",
    "#retirando os \\n\n",
    "# strip () para remover o caractere de nova linha \n",
    "# no final da linha de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yasmin/.local/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: 'U' mode is deprecated\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "path = nltk.data.find('corpora/gutenberg/melville-moby_dick.txt')\n",
    "raw = open(path, 'rU').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insira algum texto:oi\n",
      "Você digitou 1 palavras.\n"
     ]
    }
   ],
   "source": [
    "s = input ( \"Insira algum texto:\" )\n",
    "print ( \"Você digitou\" , len (word_tokenize (s)), \"palavras.\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw = open ( 'document.txt' ) .read ()\n",
    "#type (raw)   str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando tokenizamos uma string, produzimos uma lista (de palavras), e este é o tipo <list> do Python . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokens = word_tokenize (raw)\n",
    "#type (tokens) tipo list\n",
    "#words = [w.lower() for w in tokens]\n",
    "#type(words)\n",
    "#vocab = sorted(set(words))\n",
    "#type(vocab) tipo lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Monty Python'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Monty Python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Monty Python's Flying Circus\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Monty Python's Flying Circus\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Monty Python ' s Flying Circus \""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Monty Python \\' s Flying Circus '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-48-8a6d4fe0cfdc>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-48-8a6d4fe0cfdc>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    'Monty Python' s Flying Circus '\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "'Monty Python' s Flying Circus '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Devo te comparar a um dia de verão?Tu és mais amável e mais temperante:'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Devo te comparar a um dia de verão?\" \\\n",
    "\"Tu és mais amável e mais temperante:\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ventos fortes agitam os queridos botões de maio,E o contrato de verão tem data muito curta:'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "( \"Ventos fortes agitam os queridos botões de maio,\" \n",
    " \"E o contrato de verão tem data muito curta:\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Shall I compare thee to a Summer's day?\\n Thou are more lovely and more temperate:\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Shall I compare thee to a Summer's day?\n",
    " Thou are more lovely and more temperate:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Rough winds do shake the darling buds of May,\\nAnd Summer's lease hath all too short a date:\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Rough winds do shake the darling buds of May,\n",
    "And Summer's lease hath all too short a date:'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'veryveryvery'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'very' + 'very' + 'very' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'veryveryvery'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'very' * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['            very',\n",
       " '          veryvery',\n",
       " '        veryveryvery',\n",
       " '      veryveryveryvery',\n",
       " '    veryveryveryveryvery',\n",
       " '  veryveryveryveryveryvery',\n",
       " 'veryveryveryveryveryveryvery',\n",
       " '  veryveryveryveryveryvery',\n",
       " '    veryveryveryveryvery',\n",
       " '      veryveryveryvery',\n",
       " '        veryveryvery',\n",
       " '          veryvery',\n",
       " '            very']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1, 2, 3, 4, 5, 6, 7, 6, 5, 4, 3, 2, 1]\n",
    "[' ' * 2 * (7 - i) + 'very' * i for i in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'str' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-b1fef26f75b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m'very'\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m'y'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'str' and 'str'"
     ]
    }
   ],
   "source": [
    "'very' - 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'very' / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monty='oi'\n",
    "grail = 'Holy Grail'\n",
    "print(monty + grail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'monty' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-f201b89226ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrail\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'monty' is not defined"
     ]
    }
   ],
   "source": [
    "print(monty, grail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'monty' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-1e742c5336c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"and the\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrail\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'monty' is not defined"
     ]
    }
   ],
   "source": [
    "print(monty, \"and the\", grail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'monty' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-0914559737fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmonty\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'monty' is not defined"
     ]
    }
   ],
   "source": [
    "monty[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c o l o r l e s s   g r e e n   i d e a s   s l e e p   f u r i o u s l y "
     ]
    }
   ],
   "source": [
    "sent = 'colorless green ideas sleep furiously'\n",
    "for char in sent:\n",
    "    print(char, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('e', 117092), ('t', 87996), ('a', 77916), ('o', 69326), ('n', 65617)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "raw = gutenberg.raw('melville-moby_dick.txt')\n",
    "fdist = nltk.FreqDist(ch.lower() for ch in raw if ch.isalpha())\n",
    "fdist.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e',\n",
       " 't',\n",
       " 'a',\n",
       " 'o',\n",
       " 'n',\n",
       " 'i',\n",
       " 's',\n",
       " 'h',\n",
       " 'r',\n",
       " 'l',\n",
       " 'd',\n",
       " 'u',\n",
       " 'm',\n",
       " 'c',\n",
       " 'w',\n",
       " 'f',\n",
       " 'g',\n",
       " 'p',\n",
       " 'b',\n",
       " 'y',\n",
       " 'v',\n",
       " 'k',\n",
       " 'q',\n",
       " 'j',\n",
       " 'x',\n",
       " 'z']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[char for (char, count) in fdist.most_common()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fb1a9480208>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist.plot ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found \"thing\"\n"
     ]
    }
   ],
   "source": [
    "phrase = 'And now for something completely different'\n",
    "if 'thing' in phrase:\n",
    "    print('found \"thing\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'monty' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-b23952d201d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmonty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'o'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'monty' is not defined"
     ]
    }
   ],
   "source": [
    "monty.find('o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beatles = [ 'John' , 'Paul' , 'George' , 'Ringo' ]\n",
    "del beatles [-1]\n",
    "beatles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unicode para processar textos que usam conjuntos de caracteres não ASCII."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " os caracteres são entidades abstratas que podem ser realizadas como um ou mais glifos . Somente glifos podem aparecer em uma tela ou ser impressos em papel. Uma fonte é um mapeamento de caracteres a glifos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = nltk.data.find ( 'corpora / unicode_samples / polish-lat2.txt' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(path, encoding='latin2')\n",
    "for line in f:\n",
    "    line = line.strip()\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(path, encoding='latin2')\n",
    "for line in f:\n",
    "    line = line.strip()\n",
    "    print(line.encode('unicode_escape'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ord ( 'ń' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"\\u0144\"\n",
    "x.encode('utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = open (path, encoding = 'latin2' ) .readlines ()\n",
    "line = lines[5]\n",
    "print (line.encode ( 'unicode_escape' ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in line:\n",
    "    if ord(c) > 120:\n",
    "        print('{} U+{:04x}{}'.format(c.encode('utf8'), ord(c), unicodedata.name(c)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line.find('zosta\\u0142y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line.encode('unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = re.search('\\u015b\\w*', line)\n",
    "m.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenize(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist = [w for w in nltk.corpus.words.words('en') if w.islower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abaissed',\n",
       " 'abandoned',\n",
       " 'abased',\n",
       " 'abashed',\n",
       " 'abatised',\n",
       " 'abed',\n",
       " 'aborted',\n",
       " 'abridged',\n",
       " 'abscessed',\n",
       " 'absconded',\n",
       " 'absorbed',\n",
       " 'abstracted',\n",
       " 'abstricted',\n",
       " 'accelerated',\n",
       " 'accepted',\n",
       " 'accidented',\n",
       " 'accoladed',\n",
       " 'accolated',\n",
       " 'accomplished',\n",
       " 'accosted',\n",
       " 'accredited',\n",
       " 'accursed',\n",
       " 'accused',\n",
       " 'accustomed',\n",
       " 'acetated',\n",
       " 'acheweed',\n",
       " 'aciculated',\n",
       " 'aciliated',\n",
       " 'acknowledged',\n",
       " 'acorned',\n",
       " 'acquainted',\n",
       " 'acquired',\n",
       " 'acquisited',\n",
       " 'acred',\n",
       " 'aculeated',\n",
       " 'addebted',\n",
       " 'added',\n",
       " 'addicted',\n",
       " 'addlebrained',\n",
       " 'addleheaded',\n",
       " 'addlepated',\n",
       " 'addorsed',\n",
       " 'adempted',\n",
       " 'adfected',\n",
       " 'adjoined',\n",
       " 'admired',\n",
       " 'admitted',\n",
       " 'adnexed',\n",
       " 'adopted',\n",
       " 'adossed',\n",
       " 'adreamed',\n",
       " 'adscripted',\n",
       " 'aduncated',\n",
       " 'advanced',\n",
       " 'advised',\n",
       " 'aeried',\n",
       " 'aethered',\n",
       " 'afeared',\n",
       " 'affected',\n",
       " 'affectioned',\n",
       " 'affined',\n",
       " 'afflicted',\n",
       " 'affricated',\n",
       " 'affrighted',\n",
       " 'affronted',\n",
       " 'aforenamed',\n",
       " 'afterfeed',\n",
       " 'aftershafted',\n",
       " 'afterthoughted',\n",
       " 'afterwitted',\n",
       " 'agazed',\n",
       " 'aged',\n",
       " 'agglomerated',\n",
       " 'aggrieved',\n",
       " 'agminated',\n",
       " 'agnamed',\n",
       " 'agonied',\n",
       " 'agreed',\n",
       " 'agueweed',\n",
       " 'ahungered',\n",
       " 'aiguilletted',\n",
       " 'ailweed',\n",
       " 'airbrained',\n",
       " 'airified',\n",
       " 'aiseweed',\n",
       " 'aisled',\n",
       " 'alarmed',\n",
       " 'alated',\n",
       " 'alimonied',\n",
       " 'aliped',\n",
       " 'alleyed',\n",
       " 'allied',\n",
       " 'alligatored',\n",
       " 'allseed',\n",
       " 'almsdeed',\n",
       " 'aloed',\n",
       " 'altared',\n",
       " 'alveolated',\n",
       " 'amazed',\n",
       " 'ameed',\n",
       " 'amiced',\n",
       " 'amphitheatered',\n",
       " 'ampullated',\n",
       " 'amused',\n",
       " 'anchored',\n",
       " 'angled',\n",
       " 'anguiped',\n",
       " 'anguished',\n",
       " 'angulated',\n",
       " 'angulinerved',\n",
       " 'anhungered',\n",
       " 'animated',\n",
       " 'aniseed',\n",
       " 'annodated',\n",
       " 'annulated',\n",
       " 'anomaliped',\n",
       " 'anserated',\n",
       " 'anteflected',\n",
       " 'anteflexed',\n",
       " 'antimoniated',\n",
       " 'antimoniureted',\n",
       " 'antimoniuretted',\n",
       " 'antiquated',\n",
       " 'antired',\n",
       " 'antiweed',\n",
       " 'antlered',\n",
       " 'apertured',\n",
       " 'apexed',\n",
       " 'apicifixed',\n",
       " 'apiculated',\n",
       " 'apocopated',\n",
       " 'apostrophied',\n",
       " 'appearanced',\n",
       " 'appellatived',\n",
       " 'appendaged',\n",
       " 'appendiculated',\n",
       " 'applied',\n",
       " 'appressed',\n",
       " 'aralkylated',\n",
       " 'arbored',\n",
       " 'arched',\n",
       " 'architraved',\n",
       " 'arcked',\n",
       " 'arcuated',\n",
       " 'ared',\n",
       " 'areolated',\n",
       " 'ariled',\n",
       " 'arillated',\n",
       " 'armchaired',\n",
       " 'armed',\n",
       " 'armied',\n",
       " 'armillated',\n",
       " 'armored',\n",
       " 'armoried',\n",
       " 'arpeggiated',\n",
       " 'arpeggioed',\n",
       " 'arrased',\n",
       " 'arrowed',\n",
       " 'arrowheaded',\n",
       " 'arrowweed',\n",
       " 'arseneted',\n",
       " 'arsenetted',\n",
       " 'arseniureted',\n",
       " 'articled',\n",
       " 'articulated',\n",
       " 'ashamed',\n",
       " 'ashlared',\n",
       " 'ashweed',\n",
       " 'aspersed',\n",
       " 'asphyxied',\n",
       " 'assented',\n",
       " 'assessed',\n",
       " 'assigned',\n",
       " 'assistanted',\n",
       " 'associated',\n",
       " 'assonanced',\n",
       " 'assorted',\n",
       " 'assumed',\n",
       " 'assured',\n",
       " 'asteriated',\n",
       " 'astonied',\n",
       " 'aswooned',\n",
       " 'atrophiated',\n",
       " 'atrophied',\n",
       " 'attached',\n",
       " 'attired',\n",
       " 'attrited',\n",
       " 'augmented',\n",
       " 'aurated',\n",
       " 'auricled',\n",
       " 'auriculated',\n",
       " 'authorized',\n",
       " 'autoinhibited',\n",
       " 'autosensitized',\n",
       " 'autosled',\n",
       " 'averted',\n",
       " 'avowed',\n",
       " 'awearied',\n",
       " 'awned',\n",
       " 'awninged',\n",
       " 'axed',\n",
       " 'axhammered',\n",
       " 'axised',\n",
       " 'axled',\n",
       " 'axseed',\n",
       " 'axweed',\n",
       " 'azoted',\n",
       " 'azured',\n",
       " 'babied',\n",
       " 'babished',\n",
       " 'babyfied',\n",
       " 'baccated',\n",
       " 'backboned',\n",
       " 'backed',\n",
       " 'backhanded',\n",
       " 'backwatered',\n",
       " 'baconweed',\n",
       " 'badgerweed',\n",
       " 'bagged',\n",
       " 'bagwigged',\n",
       " 'baked',\n",
       " 'balanced',\n",
       " 'balconied',\n",
       " 'baldachined',\n",
       " 'baldricked',\n",
       " 'balled',\n",
       " 'ballweed',\n",
       " 'balsamweed',\n",
       " 'balustered',\n",
       " 'balustraded',\n",
       " 'bandannaed',\n",
       " 'banded',\n",
       " 'bandoleered',\n",
       " 'bangled',\n",
       " 'banked',\n",
       " 'bankweed',\n",
       " 'bannered',\n",
       " 'barbated',\n",
       " 'barbed',\n",
       " 'barebacked',\n",
       " 'bareboned',\n",
       " 'barefaced',\n",
       " 'barefooted',\n",
       " 'barehanded',\n",
       " 'bareheaded',\n",
       " 'barelegged',\n",
       " 'barenecked',\n",
       " 'barmybrained',\n",
       " 'barred',\n",
       " 'barreled',\n",
       " 'bartizaned',\n",
       " 'basebred',\n",
       " 'based',\n",
       " 'basehearted',\n",
       " 'basifixed',\n",
       " 'basilweed',\n",
       " 'basined',\n",
       " 'basinerved',\n",
       " 'basqued',\n",
       " 'bastioned',\n",
       " 'bated',\n",
       " 'bathroomed',\n",
       " 'battered',\n",
       " 'batteried',\n",
       " 'battled',\n",
       " 'battlemented',\n",
       " 'bayed',\n",
       " 'bayoneted',\n",
       " 'beached',\n",
       " 'beaded',\n",
       " 'beaked',\n",
       " 'bealtared',\n",
       " 'beamed',\n",
       " 'beanweed',\n",
       " 'beaproned',\n",
       " 'bearded',\n",
       " 'beautied',\n",
       " 'beavered',\n",
       " 'beballed',\n",
       " 'bebannered',\n",
       " 'bebed',\n",
       " 'bebelted',\n",
       " 'bebled',\n",
       " 'bebothered',\n",
       " 'bebouldered',\n",
       " 'bebuttoned',\n",
       " 'becassocked',\n",
       " 'bechained',\n",
       " 'bechignoned',\n",
       " 'becircled',\n",
       " 'becoiffed',\n",
       " 'becombed',\n",
       " 'becousined',\n",
       " 'becrinolined',\n",
       " 'becuffed',\n",
       " 'becurtained',\n",
       " 'becushioned',\n",
       " 'bed',\n",
       " 'bedaggered',\n",
       " 'bedangled',\n",
       " 'bedded',\n",
       " 'bediademed',\n",
       " 'bediamonded',\n",
       " 'beedged',\n",
       " 'beefheaded',\n",
       " 'beeheaded',\n",
       " 'beeswinged',\n",
       " 'beetled',\n",
       " 'beetleheaded',\n",
       " 'beetleweed',\n",
       " 'beeweed',\n",
       " 'befamilied',\n",
       " 'befanned',\n",
       " 'befathered',\n",
       " 'beferned',\n",
       " 'befetished',\n",
       " 'befezzed',\n",
       " 'befilleted',\n",
       " 'befilmed',\n",
       " 'beforested',\n",
       " 'befountained',\n",
       " 'befrocked',\n",
       " 'befrogged',\n",
       " 'befurbelowed',\n",
       " 'befurred',\n",
       " 'begabled',\n",
       " 'begarlanded',\n",
       " 'begartered',\n",
       " 'beggarweed',\n",
       " 'beglobed',\n",
       " 'begoggled',\n",
       " 'begowned',\n",
       " 'behatted',\n",
       " 'behaviored',\n",
       " 'beheadlined',\n",
       " 'behooped',\n",
       " 'beinked',\n",
       " 'bekilted',\n",
       " 'beknived',\n",
       " 'beknotted',\n",
       " 'belaced',\n",
       " 'belated',\n",
       " 'belatticed',\n",
       " 'belavendered',\n",
       " 'beledgered',\n",
       " 'belfried',\n",
       " 'beliked',\n",
       " 'belimousined',\n",
       " 'belled',\n",
       " 'bellied',\n",
       " 'bellmouthed',\n",
       " 'bellweed',\n",
       " 'beloved',\n",
       " 'belozenged',\n",
       " 'belted',\n",
       " 'bemazed',\n",
       " 'bemedaled',\n",
       " 'bemedalled',\n",
       " 'bemitered',\n",
       " 'bemitred',\n",
       " 'bemused',\n",
       " 'bemuslined',\n",
       " 'bended',\n",
       " 'beneaped',\n",
       " 'beneficed',\n",
       " 'beneighbored',\n",
       " 'benempted',\n",
       " 'benighted',\n",
       " 'bennetweed',\n",
       " 'benumbed',\n",
       " 'benweed',\n",
       " 'benzoated',\n",
       " 'benzoinated',\n",
       " 'bepastured',\n",
       " 'bepatched',\n",
       " 'beperiwigged',\n",
       " 'bepewed',\n",
       " 'bepillared',\n",
       " 'bepistoled',\n",
       " 'beplaided',\n",
       " 'beplumed',\n",
       " 'beribanded',\n",
       " 'beribboned',\n",
       " 'beringed',\n",
       " 'beringleted',\n",
       " 'berobed',\n",
       " 'berouged',\n",
       " 'berried',\n",
       " 'berthed',\n",
       " 'beruffed',\n",
       " 'beruffled',\n",
       " 'beshawled',\n",
       " 'besieged',\n",
       " 'beslushed',\n",
       " 'besotted',\n",
       " 'bespecked',\n",
       " 'bespectacled',\n",
       " 'besped',\n",
       " 'bespeed',\n",
       " 'bespelled',\n",
       " 'bespurred',\n",
       " 'bestatued',\n",
       " 'bestayed',\n",
       " 'bestrapped',\n",
       " 'bestubbled',\n",
       " 'besweatered',\n",
       " 'betattered',\n",
       " 'betaxed',\n",
       " 'betowered',\n",
       " 'betrothed',\n",
       " 'betrousered',\n",
       " 'betted',\n",
       " 'betuckered',\n",
       " 'beturbaned',\n",
       " 'betusked',\n",
       " 'betutored',\n",
       " 'betwattled',\n",
       " 'beuniformed',\n",
       " 'beveled',\n",
       " 'bevelled',\n",
       " 'bevesseled',\n",
       " 'bevesselled',\n",
       " 'bevined',\n",
       " 'bevoiled',\n",
       " 'bewaitered',\n",
       " 'bewhiskered',\n",
       " 'bewigged',\n",
       " 'bewildered',\n",
       " 'bewinged',\n",
       " 'bewired',\n",
       " 'bewrathed',\n",
       " 'biangulated',\n",
       " 'biarcuated',\n",
       " 'biarticulated',\n",
       " 'bicarbureted',\n",
       " 'biciliated',\n",
       " 'bicolored',\n",
       " 'bicorned',\n",
       " 'bidented',\n",
       " 'bifanged',\n",
       " 'bifidated',\n",
       " 'biflected',\n",
       " 'biforked',\n",
       " 'biformed',\n",
       " 'bifronted',\n",
       " 'bifurcated',\n",
       " 'bigeminated',\n",
       " 'bighearted',\n",
       " 'bigmouthed',\n",
       " 'bigoted',\n",
       " 'bigwigged',\n",
       " 'bilamellated',\n",
       " 'bilaminated',\n",
       " 'billed',\n",
       " 'bilobated',\n",
       " 'bilobed',\n",
       " 'bilsted',\n",
       " 'bimaculated',\n",
       " 'bimotored',\n",
       " 'bindweed',\n",
       " 'bineweed',\n",
       " 'binominated',\n",
       " 'binucleated',\n",
       " 'biparted',\n",
       " 'bipectinated',\n",
       " 'biped',\n",
       " 'bipennated',\n",
       " 'bipinnated',\n",
       " 'bipinnatiparted',\n",
       " 'bipinnatisected',\n",
       " 'biradiated',\n",
       " 'birdmouthed',\n",
       " 'birdseed',\n",
       " 'birdweed',\n",
       " 'birostrated',\n",
       " 'birthbed',\n",
       " 'bisexed',\n",
       " 'bishopweed',\n",
       " 'bistered',\n",
       " 'bistipuled',\n",
       " 'bisubstituted',\n",
       " 'bitted',\n",
       " 'bitterhearted',\n",
       " 'bitterweed',\n",
       " 'bituberculated',\n",
       " 'bitumed',\n",
       " 'bivalved',\n",
       " 'bivaulted',\n",
       " 'bivocalized',\n",
       " 'blackhearted',\n",
       " 'blackseed',\n",
       " 'blackshirted',\n",
       " 'bladderseed',\n",
       " 'bladderweed',\n",
       " 'bladed',\n",
       " 'blakeberyed',\n",
       " 'blamed',\n",
       " 'blanked',\n",
       " 'blanketed',\n",
       " 'blanketweed',\n",
       " 'blasted',\n",
       " 'bleached',\n",
       " 'bleared',\n",
       " 'bleed',\n",
       " 'blended',\n",
       " 'blessed',\n",
       " 'blighted',\n",
       " 'blinded',\n",
       " 'blindfolded',\n",
       " 'blindweed',\n",
       " 'blinked',\n",
       " 'blinkered',\n",
       " 'blistered',\n",
       " 'blisterweed',\n",
       " 'blithehearted',\n",
       " 'bloated',\n",
       " 'blobbed',\n",
       " 'blocked',\n",
       " 'blockheaded',\n",
       " 'blooded',\n",
       " 'bloodied',\n",
       " 'bloodshed',\n",
       " 'bloodstained',\n",
       " 'bloodweed',\n",
       " 'blossomed',\n",
       " 'blotched',\n",
       " 'bloused',\n",
       " 'blowzed',\n",
       " 'bludgeoned',\n",
       " 'bluebelled',\n",
       " 'bluehearted',\n",
       " 'blueweed',\n",
       " 'blunderheaded',\n",
       " 'blunthearted',\n",
       " 'blurred',\n",
       " 'bobbed',\n",
       " 'bobsled',\n",
       " 'bobtailed',\n",
       " 'bodiced',\n",
       " 'bodied',\n",
       " 'boiled',\n",
       " 'boldhearted',\n",
       " 'bolectioned',\n",
       " 'boled',\n",
       " 'boleweed',\n",
       " 'bolled',\n",
       " 'bombed',\n",
       " 'bonded',\n",
       " 'boned',\n",
       " 'boneheaded',\n",
       " 'bonneted',\n",
       " 'booked',\n",
       " 'booted',\n",
       " 'bootied',\n",
       " 'boozed',\n",
       " 'bordered',\n",
       " 'bordured',\n",
       " 'bosomed',\n",
       " 'bossed',\n",
       " 'bosselated',\n",
       " 'botched',\n",
       " 'botherheaded',\n",
       " 'bothsided',\n",
       " 'bottled',\n",
       " 'bottomed',\n",
       " 'boughed',\n",
       " 'bounded',\n",
       " 'bountied',\n",
       " 'bowed',\n",
       " 'boweled',\n",
       " 'bowlegged',\n",
       " 'bowstringed',\n",
       " 'braced',\n",
       " 'braceleted',\n",
       " 'brackened',\n",
       " 'bracted',\n",
       " 'braided',\n",
       " 'brambled',\n",
       " 'branched',\n",
       " 'branded',\n",
       " 'brandied',\n",
       " 'brangled',\n",
       " 'bravehearted',\n",
       " 'brawned',\n",
       " 'brazenfaced',\n",
       " 'breasted',\n",
       " 'breastweed',\n",
       " 'breathed',\n",
       " 'brecciated',\n",
       " 'bred',\n",
       " 'breeched',\n",
       " 'breed',\n",
       " 'breviped',\n",
       " 'bridebed',\n",
       " 'brideweed',\n",
       " 'bridged',\n",
       " 'bridled',\n",
       " 'briered',\n",
       " 'brimmed',\n",
       " 'bristled',\n",
       " 'broadhearted',\n",
       " 'brocaded',\n",
       " 'brocked',\n",
       " 'brokenhearted',\n",
       " 'bromoiodized',\n",
       " 'bronzed',\n",
       " 'brooked',\n",
       " 'brookweed',\n",
       " 'broomweed',\n",
       " 'broozled',\n",
       " 'browed',\n",
       " 'brownweed',\n",
       " 'bruckled',\n",
       " 'brushed',\n",
       " 'buboed',\n",
       " 'bucked',\n",
       " 'buckled',\n",
       " 'buckskinned',\n",
       " 'buffed',\n",
       " 'bugled',\n",
       " 'bugleweed',\n",
       " 'bugseed',\n",
       " 'bugweed',\n",
       " 'bulbed',\n",
       " 'bulked',\n",
       " 'bulkheaded',\n",
       " 'bullated',\n",
       " 'bulldogged',\n",
       " 'bulleted',\n",
       " 'bulletheaded',\n",
       " 'bullheaded',\n",
       " 'bullweed',\n",
       " 'bummed',\n",
       " 'bundlerooted',\n",
       " 'bundweed',\n",
       " 'bunted',\n",
       " 'buried',\n",
       " 'burled',\n",
       " 'burned',\n",
       " 'burnoosed',\n",
       " 'burntweed',\n",
       " 'burred',\n",
       " 'burroweed',\n",
       " 'burseed',\n",
       " 'burweed',\n",
       " 'bushed',\n",
       " 'busied',\n",
       " 'busked',\n",
       " 'buskined',\n",
       " 'busted',\n",
       " 'bustled',\n",
       " 'busybodied',\n",
       " 'buttered',\n",
       " 'butterfingered',\n",
       " 'butterweed',\n",
       " 'butteryfingered',\n",
       " 'buttocked',\n",
       " 'buttoned',\n",
       " 'buttonweed',\n",
       " 'cabled',\n",
       " 'caboshed',\n",
       " 'caddiced',\n",
       " 'caddised',\n",
       " 'cadenced',\n",
       " 'cadweed',\n",
       " 'caftaned',\n",
       " 'caged',\n",
       " 'cairned',\n",
       " 'caissoned',\n",
       " 'calced',\n",
       " 'calcified',\n",
       " 'calcined',\n",
       " 'calculated',\n",
       " 'calibered',\n",
       " 'calicoed',\n",
       " 'caligated',\n",
       " 'calpacked',\n",
       " 'calved',\n",
       " 'calycled',\n",
       " 'calyculated',\n",
       " 'camailed',\n",
       " 'camerated',\n",
       " 'cammed',\n",
       " 'campanulated',\n",
       " 'campshed',\n",
       " 'camused',\n",
       " 'canaliculated',\n",
       " 'cancellated',\n",
       " 'cancered',\n",
       " 'cancerweed',\n",
       " 'candied',\n",
       " 'candlelighted',\n",
       " 'candlesticked',\n",
       " 'candyweed',\n",
       " 'canioned',\n",
       " 'cankered',\n",
       " 'cankerweed',\n",
       " 'canned',\n",
       " 'cannelated',\n",
       " 'cannelured',\n",
       " 'cannoned',\n",
       " 'cannulated',\n",
       " 'canted',\n",
       " 'cantilevered',\n",
       " 'cantoned',\n",
       " 'cantred',\n",
       " 'caped',\n",
       " 'capernoited',\n",
       " 'capeweed',\n",
       " 'capitaled',\n",
       " 'capitated',\n",
       " 'capped',\n",
       " 'capriped',\n",
       " 'capsulated',\n",
       " 'capuched',\n",
       " 'carapaced',\n",
       " 'carbolated',\n",
       " 'carboyed',\n",
       " 'carbuncled',\n",
       " 'carcaneted',\n",
       " 'carded',\n",
       " 'carinated',\n",
       " 'carkled',\n",
       " 'carnaged',\n",
       " 'carnationed',\n",
       " 'carpetweed',\n",
       " 'carried',\n",
       " 'carrotweed',\n",
       " 'carucated',\n",
       " 'carunculated',\n",
       " 'cased',\n",
       " 'casemated',\n",
       " 'casemented',\n",
       " 'caseweed',\n",
       " 'casqued',\n",
       " 'castellated',\n",
       " 'castled',\n",
       " 'castorized',\n",
       " 'catamited',\n",
       " 'cataracted',\n",
       " 'catarrhed',\n",
       " 'catchweed',\n",
       " 'catenated',\n",
       " 'caterpillared',\n",
       " 'catfaced',\n",
       " 'catfooted',\n",
       " 'cathedraled',\n",
       " 'caudated',\n",
       " 'caverned',\n",
       " 'cavitied',\n",
       " 'cayenned',\n",
       " 'cedared',\n",
       " 'ceilinged',\n",
       " 'celebrated',\n",
       " 'cellated',\n",
       " 'celled',\n",
       " 'cellulated',\n",
       " 'celluloided',\n",
       " 'centered',\n",
       " 'centriffed',\n",
       " 'centuried',\n",
       " 'cerated',\n",
       " 'cered',\n",
       " 'certified',\n",
       " 'chafeweed',\n",
       " 'chaffseed',\n",
       " 'chaffweed',\n",
       " 'chafted',\n",
       " 'chained',\n",
       " 'chaliced',\n",
       " 'chambered',\n",
       " 'chamberleted',\n",
       " 'chamberletted',\n",
       " 'chanceled',\n",
       " 'channeled',\n",
       " 'channelled',\n",
       " 'chaped',\n",
       " 'chapleted',\n",
       " 'chapournetted',\n",
       " 'chapped',\n",
       " 'charioted',\n",
       " 'charqued',\n",
       " 'chartered',\n",
       " 'chasmed',\n",
       " 'chasteweed',\n",
       " 'chasubled',\n",
       " 'checked',\n",
       " 'checkered',\n",
       " 'checkrowed',\n",
       " 'cheered',\n",
       " 'cheliped',\n",
       " 'cherried',\n",
       " 'chickenbreasted',\n",
       " 'chickenhearted',\n",
       " 'chickenweed',\n",
       " 'chickweed',\n",
       " 'chicqued',\n",
       " 'chiggerweed',\n",
       " 'chignoned',\n",
       " 'childbed',\n",
       " 'childed',\n",
       " 'chilled',\n",
       " 'chined',\n",
       " 'chinned',\n",
       " 'chipped',\n",
       " 'chiseled',\n",
       " 'chitinized',\n",
       " 'chokered',\n",
       " 'chokeweed',\n",
       " 'cholterheaded',\n",
       " 'chopped',\n",
       " 'choppered',\n",
       " 'chorded',\n",
       " 'chowderheaded',\n",
       " 'christened',\n",
       " 'chubbed',\n",
       " 'chuckleheaded',\n",
       " 'churchified',\n",
       " 'churled',\n",
       " 'ciliated',\n",
       " 'cingulated',\n",
       " 'cinnamoned',\n",
       " 'cinquefoiled',\n",
       " 'circled',\n",
       " 'circumscribed',\n",
       " 'circumstanced',\n",
       " 'cirrated',\n",
       " 'cirrhosed',\n",
       " 'cirriped',\n",
       " 'cisted',\n",
       " 'citied',\n",
       " 'citified',\n",
       " 'citrated',\n",
       " 'civilized',\n",
       " 'clammed',\n",
       " 'clammyweed',\n",
       " 'clanned',\n",
       " 'clapped',\n",
       " 'classed',\n",
       " 'classified',\n",
       " 'clavated',\n",
       " 'clavellated',\n",
       " 'clawed',\n",
       " 'claybrained',\n",
       " 'clayweed',\n",
       " 'cleaded',\n",
       " 'cleanhanded',\n",
       " 'cleanhearted',\n",
       " 'clearheaded',\n",
       " 'clearhearted',\n",
       " 'clearweed',\n",
       " 'cled',\n",
       " 'cleeked',\n",
       " 'clefted',\n",
       " 'clerestoried',\n",
       " 'cliented',\n",
       " 'cliffed',\n",
       " 'cliffweed',\n",
       " 'clipped',\n",
       " 'cloaked',\n",
       " 'clocked',\n",
       " 'clodpated',\n",
       " 'cloistered',\n",
       " 'closed',\n",
       " 'closefisted',\n",
       " 'closehanded',\n",
       " 'closehearted',\n",
       " 'closemouthed',\n",
       " 'clotweed',\n",
       " 'clouded',\n",
       " 'clouted',\n",
       " 'clovered',\n",
       " 'clubbed',\n",
       " 'clubfisted',\n",
       " 'clubfooted',\n",
       " 'clubweed',\n",
       " 'clustered',\n",
       " 'coaged',\n",
       " 'coaggregated',\n",
       " 'coated',\n",
       " 'coattailed',\n",
       " 'cobbed',\n",
       " 'cocashweed',\n",
       " 'cochleated',\n",
       " 'cockaded',\n",
       " 'cocked',\n",
       " 'cockeyed',\n",
       " 'cockled',\n",
       " 'cockneybred',\n",
       " 'cockscombed',\n",
       " 'cockweed',\n",
       " 'codheaded',\n",
       " 'coed',\n",
       " 'coelongated',\n",
       " 'coembedded',\n",
       " 'coequated',\n",
       " 'coexpanded',\n",
       " 'coffeeweed',\n",
       " 'cogged',\n",
       " 'coifed',\n",
       " 'coiled',\n",
       " 'coldhearted',\n",
       " 'coleseed',\n",
       " 'colicweed',\n",
       " 'collared',\n",
       " 'collected',\n",
       " 'collied',\n",
       " 'colloped',\n",
       " 'colonnaded',\n",
       " 'colored',\n",
       " 'columnated',\n",
       " 'columned',\n",
       " 'combed',\n",
       " 'combined',\n",
       " 'compacted',\n",
       " 'complected',\n",
       " 'complexioned',\n",
       " 'complicated',\n",
       " 'componed',\n",
       " 'componented',\n",
       " 'composed',\n",
       " 'compressed',\n",
       " 'comprised',\n",
       " 'compulsed',\n",
       " 'conamed',\n",
       " 'concamerated',\n",
       " 'concealed',\n",
       " 'conceded',\n",
       " 'conceited',\n",
       " 'concentrated',\n",
       " 'concerned',\n",
       " 'concerted',\n",
       " 'conched',\n",
       " 'conchyliated',\n",
       " 'condemned',\n",
       " 'condensed',\n",
       " 'conditioned',\n",
       " 'conduplicated',\n",
       " 'coned',\n",
       " 'confated',\n",
       " 'conferted',\n",
       " 'confined',\n",
       " 'confirmed',\n",
       " 'conflated',\n",
       " 'confounded',\n",
       " 'confused',\n",
       " 'congested',\n",
       " 'conjoined',\n",
       " 'conjugated',\n",
       " 'connected',\n",
       " 'conred',\n",
       " 'consecrated',\n",
       " 'considered',\n",
       " 'consolidated',\n",
       " 'constrained',\n",
       " 'constricted',\n",
       " 'consumpted',\n",
       " 'contagioned',\n",
       " 'contented',\n",
       " 'contextured',\n",
       " 'continued',\n",
       " 'contorted',\n",
       " 'contortioned',\n",
       " 'contracted',\n",
       " 'contractured',\n",
       " 'contusioned',\n",
       " 'converted',\n",
       " 'convexed',\n",
       " 'convinced',\n",
       " 'convoluted',\n",
       " 'coolheaded',\n",
       " 'coolweed',\n",
       " 'copied',\n",
       " 'copleased',\n",
       " 'copped',\n",
       " 'coppernosed',\n",
       " 'copperytailed',\n",
       " 'coppiced',\n",
       " 'coppled',\n",
       " 'copsewooded',\n",
       " 'copygraphed',\n",
       " 'coraled',\n",
       " 'corded',\n",
       " 'corduroyed',\n",
       " 'cored',\n",
       " 'coreflexed',\n",
       " 'corked',\n",
       " 'cornered',\n",
       " 'cornified',\n",
       " 'cornuated',\n",
       " 'cornuted',\n",
       " 'corollated',\n",
       " 'coronaled',\n",
       " 'coronated',\n",
       " 'coroneted',\n",
       " 'coronetted',\n",
       " 'corpusculated',\n",
       " 'corrected',\n",
       " 'correlated',\n",
       " 'corridored',\n",
       " ...]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in wordlist if re.search('ed$', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abjectly',\n",
       " 'adjuster',\n",
       " 'dejected',\n",
       " 'dejectly',\n",
       " 'injector',\n",
       " 'majestic',\n",
       " 'objectee',\n",
       " 'objector',\n",
       " 'rejecter',\n",
       " 'rejector',\n",
       " 'unjilted',\n",
       " 'unjolted',\n",
       " 'unjustly']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in wordlist if re.search('^..j..t..$', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(1 for w in text if re.search('^e-?mail$', w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gold', 'golf', 'hold', 'hole']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in wordlist if re.search('^[ghi][mno][jlk][def]$', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['miiiiiiiiiiiiinnnnnnnnnnneeeeeeeeee',\n",
       " 'miiiiiinnnnnnnnnneeeeeeee',\n",
       " 'mine',\n",
       " 'mmmmmmmmiiiiiiiiinnnnnnnnneeeeeeee']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_words = sorted(set(w for w in nltk.corpus.nps_chat.words()))\n",
    "[w for w in chat_words if re.search('^m+i+n+e+$', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'aaaaaaaaaaaaaaaaa',\n",
       " 'aaahhhh',\n",
       " 'ah',\n",
       " 'ahah',\n",
       " 'ahahah',\n",
       " 'ahh',\n",
       " 'ahhahahaha',\n",
       " 'ahhh',\n",
       " 'ahhhh',\n",
       " 'ahhhhhh',\n",
       " 'ahhhhhhhhhhhhhh',\n",
       " 'h',\n",
       " 'ha',\n",
       " 'haaa',\n",
       " 'hah',\n",
       " 'haha',\n",
       " 'hahaaa',\n",
       " 'hahah',\n",
       " 'hahaha',\n",
       " 'hahahaa',\n",
       " 'hahahah',\n",
       " 'hahahaha',\n",
       " 'hahahahaaa',\n",
       " 'hahahahahaha',\n",
       " 'hahahahahahaha',\n",
       " 'hahahahahahahahahahahahahahahaha',\n",
       " 'hahahhahah',\n",
       " 'hahhahahaha']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " [w for w in chat_words if re.search('^[ha]+$', w)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"+\" significa simplesmente \"uma ou mais instâncias do item anterior\"\n",
    "\"*\" , que significa \"zero ou mais instâncias do item anterior\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'e',\n",
       " 'i',\n",
       " 'in',\n",
       " 'm',\n",
       " 'me',\n",
       " 'meeeeeeeeeeeee',\n",
       " 'mi',\n",
       " 'miiiiiiiiiiiiinnnnnnnnnnneeeeeeeeee',\n",
       " 'miiiiiinnnnnnnnnneeeeeeee',\n",
       " 'min',\n",
       " 'mine',\n",
       " 'mm',\n",
       " 'mmm',\n",
       " 'mmmm',\n",
       " 'mmmmm',\n",
       " 'mmmmmm',\n",
       " 'mmmmmmmmiiiiiiiiinnnnnnnnneeeeeeee',\n",
       " 'mmmmmmmmmm',\n",
       " 'mmmmmmmmmmmmm',\n",
       " 'mmmmmmmmmmmmmm',\n",
       " 'n',\n",
       " 'ne']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in chat_words if re.search('^m*i*n*e*$', w)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[^ 123] ^fica um not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.0085',\n",
       " '0.05',\n",
       " '0.1',\n",
       " '0.16',\n",
       " '0.2',\n",
       " '0.25',\n",
       " '0.28',\n",
       " '0.3',\n",
       " '0.4',\n",
       " '0.5',\n",
       " '0.50',\n",
       " '0.54',\n",
       " '0.56',\n",
       " '0.60',\n",
       " '0.7',\n",
       " '0.82',\n",
       " '0.84',\n",
       " '0.9',\n",
       " '0.95',\n",
       " '0.99',\n",
       " '1.01',\n",
       " '1.1',\n",
       " '1.125',\n",
       " '1.14',\n",
       " '1.1650',\n",
       " '1.17',\n",
       " '1.18',\n",
       " '1.19',\n",
       " '1.2',\n",
       " '1.20',\n",
       " '1.24',\n",
       " '1.25',\n",
       " '1.26',\n",
       " '1.28',\n",
       " '1.35',\n",
       " '1.39',\n",
       " '1.4',\n",
       " '1.457',\n",
       " '1.46',\n",
       " '1.49',\n",
       " '1.5',\n",
       " '1.50',\n",
       " '1.55',\n",
       " '1.56',\n",
       " '1.5755',\n",
       " '1.5805',\n",
       " '1.6',\n",
       " '1.61',\n",
       " '1.637',\n",
       " '1.64',\n",
       " '1.65',\n",
       " '1.7',\n",
       " '1.75',\n",
       " '1.76',\n",
       " '1.8',\n",
       " '1.82',\n",
       " '1.8415',\n",
       " '1.85',\n",
       " '1.8500',\n",
       " '1.9',\n",
       " '1.916',\n",
       " '1.92',\n",
       " '10.19',\n",
       " '10.2',\n",
       " '10.5',\n",
       " '107.03',\n",
       " '107.9',\n",
       " '109.73',\n",
       " '11.10',\n",
       " '11.5',\n",
       " '11.57',\n",
       " '11.6',\n",
       " '11.72',\n",
       " '11.95',\n",
       " '112.9',\n",
       " '113.2',\n",
       " '116.3',\n",
       " '116.4',\n",
       " '116.7',\n",
       " '116.9',\n",
       " '118.6',\n",
       " '12.09',\n",
       " '12.5',\n",
       " '12.52',\n",
       " '12.68',\n",
       " '12.7',\n",
       " '12.82',\n",
       " '12.97',\n",
       " '120.7',\n",
       " '1206.26',\n",
       " '121.6',\n",
       " '126.1',\n",
       " '126.15',\n",
       " '127.03',\n",
       " '129.91',\n",
       " '13.1',\n",
       " '13.15',\n",
       " '13.5',\n",
       " '13.50',\n",
       " '13.625',\n",
       " '13.65',\n",
       " '13.73',\n",
       " '13.8',\n",
       " '13.90',\n",
       " '130.6',\n",
       " '130.7',\n",
       " '131.01',\n",
       " '132.9',\n",
       " '133.7',\n",
       " '133.8',\n",
       " '14.00',\n",
       " '14.13',\n",
       " '14.26',\n",
       " '14.28',\n",
       " '14.43',\n",
       " '14.5',\n",
       " '14.53',\n",
       " '14.54',\n",
       " '14.6',\n",
       " '14.75',\n",
       " '14.99',\n",
       " '141.9',\n",
       " '142.84',\n",
       " '142.85',\n",
       " '143.08',\n",
       " '143.80',\n",
       " '143.93',\n",
       " '148.9',\n",
       " '149.9',\n",
       " '15.5',\n",
       " '150.00',\n",
       " '153.3',\n",
       " '154.2',\n",
       " '16.05',\n",
       " '16.09',\n",
       " '16.125',\n",
       " '16.2',\n",
       " '16.5',\n",
       " '16.68',\n",
       " '16.7',\n",
       " '16.9',\n",
       " '169.9',\n",
       " '17.3',\n",
       " '17.4',\n",
       " '17.5',\n",
       " '17.95',\n",
       " '1738.1',\n",
       " '176.1',\n",
       " '18.3',\n",
       " '18.6',\n",
       " '18.95',\n",
       " '185.9',\n",
       " '188.84',\n",
       " '19.3',\n",
       " '19.50',\n",
       " '19.6',\n",
       " '19.94',\n",
       " '19.95',\n",
       " '191.9',\n",
       " '2.07',\n",
       " '2.1',\n",
       " '2.15',\n",
       " '2.19',\n",
       " '2.2',\n",
       " '2.25',\n",
       " '2.29',\n",
       " '2.3',\n",
       " '2.30',\n",
       " '2.35',\n",
       " '2.375',\n",
       " '2.4',\n",
       " '2.42',\n",
       " '2.44',\n",
       " '2.46',\n",
       " '2.47',\n",
       " '2.5',\n",
       " '2.50',\n",
       " '2.6',\n",
       " '2.62',\n",
       " '2.65',\n",
       " '2.7',\n",
       " '2.75',\n",
       " '2.8',\n",
       " '2.80',\n",
       " '2.87',\n",
       " '2.875',\n",
       " '2.9',\n",
       " '2.95',\n",
       " '20.07',\n",
       " '20.5',\n",
       " '21.1',\n",
       " '21.9',\n",
       " '2141.7',\n",
       " '2160.1',\n",
       " '2163.2',\n",
       " '22.75',\n",
       " '220.45',\n",
       " '221.4',\n",
       " '225.6',\n",
       " '23.25',\n",
       " '23.4',\n",
       " '23.5',\n",
       " '23.72',\n",
       " '234.4',\n",
       " '236.74',\n",
       " '236.79',\n",
       " '24.95',\n",
       " '25.50',\n",
       " '25.6',\n",
       " '251.2',\n",
       " '26.2',\n",
       " '26.5',\n",
       " '26.8',\n",
       " '263.07',\n",
       " '2645.90',\n",
       " '2691.19',\n",
       " '27.1',\n",
       " '27.4',\n",
       " '273.5',\n",
       " '278.7',\n",
       " '28.25',\n",
       " '28.36',\n",
       " '28.4',\n",
       " '28.5',\n",
       " '28.53',\n",
       " '28.6',\n",
       " '29.3',\n",
       " '29.4',\n",
       " '29.9',\n",
       " '292.32',\n",
       " '3.01',\n",
       " '3.04',\n",
       " '3.1',\n",
       " '3.16',\n",
       " '3.18',\n",
       " '3.19',\n",
       " '3.2',\n",
       " '3.20',\n",
       " '3.23',\n",
       " '3.253',\n",
       " '3.28',\n",
       " '3.3',\n",
       " '3.35',\n",
       " '3.375',\n",
       " '3.4',\n",
       " '3.42',\n",
       " '3.43',\n",
       " '3.5',\n",
       " '3.55',\n",
       " '3.6',\n",
       " '3.61',\n",
       " '3.625',\n",
       " '3.7',\n",
       " '3.75',\n",
       " '3.8',\n",
       " '3.80',\n",
       " '3.9',\n",
       " '30.6',\n",
       " '30.9',\n",
       " '319.75',\n",
       " '32.8',\n",
       " '334.5',\n",
       " '34.625',\n",
       " '341.20',\n",
       " '3436.58',\n",
       " '35.2',\n",
       " '35.7',\n",
       " '352.7',\n",
       " '352.9',\n",
       " '35500.64',\n",
       " '35564.43',\n",
       " '36.9',\n",
       " '361.8',\n",
       " '3648.82',\n",
       " '37.3',\n",
       " '37.5',\n",
       " '372.14',\n",
       " '372.9',\n",
       " '374.19',\n",
       " '374.20',\n",
       " '377.60',\n",
       " '38.3',\n",
       " '38.375',\n",
       " '38.5',\n",
       " '38.875',\n",
       " '387.8',\n",
       " '4.1',\n",
       " '4.10',\n",
       " '4.2',\n",
       " '4.25',\n",
       " '4.3',\n",
       " '4.4',\n",
       " '4.5',\n",
       " '4.55',\n",
       " '4.6',\n",
       " '4.7',\n",
       " '4.75',\n",
       " '4.8',\n",
       " '4.875',\n",
       " '4.898',\n",
       " '4.9',\n",
       " '40.21',\n",
       " '41.60',\n",
       " '415.6',\n",
       " '415.8',\n",
       " '42.1',\n",
       " '42.5',\n",
       " '422.5',\n",
       " '43.875',\n",
       " '434.4',\n",
       " '436.01',\n",
       " '446.62',\n",
       " '449.04',\n",
       " '45.2',\n",
       " '45.3',\n",
       " '45.75',\n",
       " '456.64',\n",
       " '46.1',\n",
       " '47.1',\n",
       " '47.125',\n",
       " '47.5',\n",
       " '47.6',\n",
       " '49.9',\n",
       " '494.50',\n",
       " '497.34',\n",
       " '5.1',\n",
       " '5.2180',\n",
       " '5.276',\n",
       " '5.29',\n",
       " '5.3',\n",
       " '5.39',\n",
       " '5.4',\n",
       " '5.435',\n",
       " '5.5',\n",
       " '5.57',\n",
       " '5.6',\n",
       " '5.63',\n",
       " '5.7',\n",
       " '5.70',\n",
       " '5.8',\n",
       " '5.82',\n",
       " '5.9',\n",
       " '5.92',\n",
       " '50.1',\n",
       " '50.38',\n",
       " '50.45',\n",
       " '51.25',\n",
       " '51.6',\n",
       " '55.1',\n",
       " '566.54',\n",
       " '57.50',\n",
       " '57.6',\n",
       " '57.7',\n",
       " '58.64',\n",
       " '59.6',\n",
       " '59.9',\n",
       " '6.03',\n",
       " '6.1',\n",
       " '6.20',\n",
       " '6.21',\n",
       " '6.25',\n",
       " '6.4',\n",
       " '6.40',\n",
       " '6.44',\n",
       " '6.5',\n",
       " '6.50',\n",
       " '6.53',\n",
       " '6.6',\n",
       " '6.7',\n",
       " '6.70',\n",
       " '6.79',\n",
       " '6.84',\n",
       " '6.9',\n",
       " '60.36',\n",
       " '618.1',\n",
       " '62.1',\n",
       " '62.5',\n",
       " '62.625',\n",
       " '63.79',\n",
       " '630.9',\n",
       " '64.5',\n",
       " '66.5',\n",
       " '7.15',\n",
       " '7.2',\n",
       " '7.20',\n",
       " '7.272',\n",
       " '7.3',\n",
       " '7.4',\n",
       " '7.40',\n",
       " '7.422',\n",
       " '7.45',\n",
       " '7.458',\n",
       " '7.5',\n",
       " '7.50',\n",
       " '7.52',\n",
       " '7.55',\n",
       " '7.60',\n",
       " '7.62',\n",
       " '7.63',\n",
       " '7.65',\n",
       " '7.74',\n",
       " '7.78',\n",
       " '7.79',\n",
       " '7.8',\n",
       " '7.80',\n",
       " '7.84',\n",
       " '7.88',\n",
       " '7.90',\n",
       " '7.95',\n",
       " '70.2',\n",
       " '70.7',\n",
       " '705.6',\n",
       " '72.7',\n",
       " '734.9',\n",
       " '737.5',\n",
       " '77.56',\n",
       " '77.6',\n",
       " '77.70',\n",
       " '8.04',\n",
       " '8.06',\n",
       " '8.07',\n",
       " '8.1',\n",
       " '8.12',\n",
       " '8.14',\n",
       " '8.15',\n",
       " '8.19',\n",
       " '8.2',\n",
       " '8.22',\n",
       " '8.25',\n",
       " '8.30',\n",
       " '8.35',\n",
       " '8.45',\n",
       " '8.467',\n",
       " '8.47',\n",
       " '8.48',\n",
       " '8.5',\n",
       " '8.50',\n",
       " '8.53',\n",
       " '8.55',\n",
       " '8.56',\n",
       " '8.575',\n",
       " '8.60',\n",
       " '8.64',\n",
       " '8.65',\n",
       " '8.70',\n",
       " '8.75',\n",
       " '8.9',\n",
       " '80.50',\n",
       " '80.8',\n",
       " '81.8',\n",
       " '811.9',\n",
       " '83.4',\n",
       " '84.29',\n",
       " '84.9',\n",
       " '85.1',\n",
       " '85.7',\n",
       " '86.12',\n",
       " '87.5',\n",
       " '88.32',\n",
       " '89.7',\n",
       " '89.9',\n",
       " '9.3',\n",
       " '9.32',\n",
       " '9.37',\n",
       " '9.45',\n",
       " '9.5',\n",
       " '9.625',\n",
       " '9.75',\n",
       " '9.8',\n",
       " '9.82',\n",
       " '9.9',\n",
       " '92.9',\n",
       " '93.3',\n",
       " '93.9',\n",
       " '94.2',\n",
       " '94.8',\n",
       " '95.09',\n",
       " '96.4',\n",
       " '98.3',\n",
       " '99.1',\n",
       " '99.3']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wsj = sorted(set(nltk.corpus.treebank.words()))\n",
    "[w for w in wsj if re.search('^[0-9]+\\.[0-9]+$', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C$', 'US$']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in wsj if re.search('^[A-Z]+\\$$', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1614',\n",
       " '1637',\n",
       " '1787',\n",
       " '1901',\n",
       " '1903',\n",
       " '1917',\n",
       " '1925',\n",
       " '1929',\n",
       " '1933',\n",
       " '1934',\n",
       " '1948',\n",
       " '1953',\n",
       " '1955',\n",
       " '1956',\n",
       " '1961',\n",
       " '1965',\n",
       " '1966',\n",
       " '1967',\n",
       " '1968',\n",
       " '1969',\n",
       " '1970',\n",
       " '1971',\n",
       " '1972',\n",
       " '1973',\n",
       " '1975',\n",
       " '1976',\n",
       " '1977',\n",
       " '1979',\n",
       " '1980',\n",
       " '1981',\n",
       " '1982',\n",
       " '1983',\n",
       " '1984',\n",
       " '1985',\n",
       " '1986',\n",
       " '1987',\n",
       " '1988',\n",
       " '1989',\n",
       " '1990',\n",
       " '1991',\n",
       " '1992',\n",
       " '1993',\n",
       " '1994',\n",
       " '1995',\n",
       " '1996',\n",
       " '1997',\n",
       " '1998',\n",
       " '1999',\n",
       " '2000',\n",
       " '2005',\n",
       " '2009',\n",
       " '2017',\n",
       " '2019',\n",
       " '2029',\n",
       " '3057',\n",
       " '8300']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in wsj if re.search('^[0-9]{4}$', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10-day',\n",
       " '10-lap',\n",
       " '10-year',\n",
       " '100-share',\n",
       " '12-point',\n",
       " '12-year',\n",
       " '14-hour',\n",
       " '15-day',\n",
       " '150-point',\n",
       " '190-point',\n",
       " '20-point',\n",
       " '20-stock',\n",
       " '21-month',\n",
       " '237-seat',\n",
       " '240-page',\n",
       " '27-year',\n",
       " '30-day',\n",
       " '30-point',\n",
       " '30-share',\n",
       " '30-year',\n",
       " '300-day',\n",
       " '36-day',\n",
       " '36-store',\n",
       " '42-year',\n",
       " '50-state',\n",
       " '500-stock',\n",
       " '52-week',\n",
       " '69-point',\n",
       " '84-month',\n",
       " '87-store',\n",
       " '90-day']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in wsj if re.search('^[0-9]+-[a-z]{3,5}$', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['black-and-white',\n",
       " 'bread-and-butter',\n",
       " 'father-in-law',\n",
       " 'machine-gun-toting',\n",
       " 'savings-and-loan']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in wsj if re.search('^[a-z]{5,}-[a-z]{2,3}-[a-z]{,6}$', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['62%-owned',\n",
       " 'Absorbed',\n",
       " 'According',\n",
       " 'Adopting',\n",
       " 'Advanced',\n",
       " 'Advancing',\n",
       " 'Alfred',\n",
       " 'Allied',\n",
       " 'Annualized',\n",
       " 'Anything',\n",
       " 'Arbitrage-related',\n",
       " 'Arbitraging',\n",
       " 'Asked',\n",
       " 'Assuming',\n",
       " 'Atlanta-based',\n",
       " 'Baking',\n",
       " 'Banking',\n",
       " 'Beginning',\n",
       " 'Beijing',\n",
       " 'Being',\n",
       " 'Bermuda-based',\n",
       " 'Betting',\n",
       " 'Boeing',\n",
       " 'Broadcasting',\n",
       " 'Bucking',\n",
       " 'Buying',\n",
       " 'Calif.-based',\n",
       " 'Change-ringing',\n",
       " 'Citing',\n",
       " 'Concerned',\n",
       " 'Confronted',\n",
       " 'Conn.based',\n",
       " 'Consolidated',\n",
       " 'Continued',\n",
       " 'Continuing',\n",
       " 'Declining',\n",
       " 'Defending',\n",
       " 'Depending',\n",
       " 'Designated',\n",
       " 'Determining',\n",
       " 'Developed',\n",
       " 'Died',\n",
       " 'During',\n",
       " 'Encouraged',\n",
       " 'Encouraging',\n",
       " 'English-speaking',\n",
       " 'Estimated',\n",
       " 'Everything',\n",
       " 'Excluding',\n",
       " 'Exxon-owned',\n",
       " 'Faulding',\n",
       " 'Fed',\n",
       " 'Feeding',\n",
       " 'Filling',\n",
       " 'Filmed',\n",
       " 'Financing',\n",
       " 'Following',\n",
       " 'Founded',\n",
       " 'Fracturing',\n",
       " 'Francisco-based',\n",
       " 'Fred',\n",
       " 'Funded',\n",
       " 'Funding',\n",
       " 'Generalized',\n",
       " 'Germany-based',\n",
       " 'Getting',\n",
       " 'Guaranteed',\n",
       " 'Having',\n",
       " 'Heating',\n",
       " 'Heightened',\n",
       " 'Holding',\n",
       " 'Housing',\n",
       " 'Illuminating',\n",
       " 'Indeed',\n",
       " 'Indexing',\n",
       " 'Irving',\n",
       " 'Jersey-based',\n",
       " 'Judging',\n",
       " 'Knowing',\n",
       " 'Learning',\n",
       " 'Legislating',\n",
       " 'Leming',\n",
       " 'Limited',\n",
       " 'London-based',\n",
       " 'Manfred',\n",
       " 'Manufacturing',\n",
       " 'Melamed',\n",
       " 'Miami-based',\n",
       " 'Mich.-based',\n",
       " 'Mining',\n",
       " 'Minneapolis-based',\n",
       " 'Mo.-based',\n",
       " 'Mortgage-Backed',\n",
       " 'Moving',\n",
       " 'Muzzling',\n",
       " 'N.J.-based',\n",
       " 'NBC-owned',\n",
       " 'NIH-appointed',\n",
       " 'Named',\n",
       " 'No-Smoking',\n",
       " 'Observing',\n",
       " 'Offering',\n",
       " 'Ohio-based',\n",
       " 'Orleans-based',\n",
       " 'Packaging',\n",
       " 'Performing',\n",
       " 'Philadelphia-based',\n",
       " 'Posted',\n",
       " 'Provided',\n",
       " 'Publishing',\n",
       " 'Purchasing',\n",
       " 'Rated',\n",
       " 'Reached',\n",
       " 'Red',\n",
       " 'Red-blooded',\n",
       " 'Reducing',\n",
       " 'Reed',\n",
       " 'Regarded',\n",
       " 'Rekindled',\n",
       " 'Related',\n",
       " 'Ringing',\n",
       " 'Rolling',\n",
       " 'Sacramento-based',\n",
       " 'Scoring',\n",
       " 'Seattle-based',\n",
       " 'Seed',\n",
       " 'Skilled',\n",
       " 'Smelting',\n",
       " 'Something',\n",
       " 'Spending',\n",
       " 'Standardized',\n",
       " 'Standing',\n",
       " 'Starting',\n",
       " 'Sterling',\n",
       " 'Taking',\n",
       " 'Texas-based',\n",
       " 'Toronto-based',\n",
       " 'Traded',\n",
       " 'Trading',\n",
       " 'Troubled',\n",
       " 'U.N.-supervised',\n",
       " 'U.S.-backed',\n",
       " 'United',\n",
       " 'Used',\n",
       " 'Varying',\n",
       " 'Washington-based',\n",
       " 'Whiting',\n",
       " 'Wilfred',\n",
       " 'Winning',\n",
       " 'Xiaoping',\n",
       " 'York-based',\n",
       " 'Zayed',\n",
       " 'abandoned',\n",
       " 'abating',\n",
       " 'abolishing',\n",
       " 'abortion-related',\n",
       " 'abounding',\n",
       " 'abridging',\n",
       " 'absorbed',\n",
       " 'acceded',\n",
       " 'accelerated',\n",
       " 'accepted',\n",
       " 'accepting',\n",
       " 'according',\n",
       " 'accounted',\n",
       " 'accounting',\n",
       " 'accrued',\n",
       " 'accumulated',\n",
       " 'accused',\n",
       " 'accusing',\n",
       " 'achieved',\n",
       " 'achieving',\n",
       " 'acknowledging',\n",
       " 'acquired',\n",
       " 'acquiring',\n",
       " 'acquisition-minded',\n",
       " 'acted',\n",
       " 'acting',\n",
       " 'adapted',\n",
       " 'adapting',\n",
       " 'added',\n",
       " 'adding',\n",
       " 'addressing',\n",
       " 'adjusted',\n",
       " 'adjusting',\n",
       " 'admitted',\n",
       " 'admitting',\n",
       " 'adopted',\n",
       " 'advanced',\n",
       " 'advancing',\n",
       " 'advertised',\n",
       " 'advertising',\n",
       " 'advised',\n",
       " 'advocated',\n",
       " 'advocating',\n",
       " 'affecting',\n",
       " 'afflicted',\n",
       " 'aggravated',\n",
       " 'agreed',\n",
       " 'agreeing',\n",
       " 'ailing',\n",
       " 'aimed',\n",
       " 'aiming',\n",
       " 'aired',\n",
       " 'airline-related',\n",
       " 'alarmed',\n",
       " 'alienated',\n",
       " 'alleged',\n",
       " 'alleging',\n",
       " 'allocated',\n",
       " 'allowed',\n",
       " 'altered',\n",
       " 'altering',\n",
       " 'amended',\n",
       " 'amending',\n",
       " 'amounted',\n",
       " 'amusing',\n",
       " 'angered',\n",
       " 'announced',\n",
       " 'annoyed',\n",
       " 'annualized',\n",
       " 'answered',\n",
       " 'anti-dumping',\n",
       " 'anticipated',\n",
       " 'anticipating',\n",
       " 'anything',\n",
       " 'apologizing',\n",
       " 'appealing',\n",
       " 'appeared',\n",
       " 'appearing',\n",
       " 'applied',\n",
       " 'appointed',\n",
       " 'approached',\n",
       " 'appropriated',\n",
       " 'approved',\n",
       " 'arched',\n",
       " 'argued',\n",
       " 'arguing',\n",
       " 'arising',\n",
       " 'armed',\n",
       " 'arranged',\n",
       " 'arrested',\n",
       " 'arrived',\n",
       " 'asbestos-related',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'assassinated',\n",
       " 'assembled',\n",
       " 'asserted',\n",
       " 'asserting',\n",
       " 'assessed',\n",
       " 'assigned',\n",
       " 'assisted',\n",
       " 'associated',\n",
       " 'assumed',\n",
       " 'assuming',\n",
       " 'assured',\n",
       " 'attached',\n",
       " 'attacking',\n",
       " 'attempted',\n",
       " 'attempting',\n",
       " 'attended',\n",
       " 'attending',\n",
       " 'attracted',\n",
       " 'attracting',\n",
       " 'attributed',\n",
       " 'auctioned',\n",
       " 'authorized',\n",
       " 'authorizing',\n",
       " 'automated',\n",
       " 'automotive-lighting',\n",
       " 'averaged',\n",
       " 'averted',\n",
       " 'avoiding',\n",
       " 'awarded',\n",
       " 'awarding',\n",
       " 'backed',\n",
       " 'backing',\n",
       " 'balanced',\n",
       " 'bald-faced',\n",
       " 'balkanized',\n",
       " 'balked',\n",
       " 'balloting',\n",
       " 'bank-backed',\n",
       " 'banking',\n",
       " 'banned',\n",
       " 'banning',\n",
       " 'barking',\n",
       " 'barred',\n",
       " 'based',\n",
       " 'battered',\n",
       " 'battery-operated',\n",
       " 'batting',\n",
       " 'bearing',\n",
       " 'becoming',\n",
       " 'bedding',\n",
       " 'befuddled',\n",
       " 'beginning',\n",
       " 'behaving',\n",
       " 'beheading',\n",
       " 'being',\n",
       " 'beleaguered',\n",
       " 'believed',\n",
       " 'bell-ringing',\n",
       " 'belonging',\n",
       " 'benefited',\n",
       " 'best-selling',\n",
       " 'betting',\n",
       " 'bickering',\n",
       " 'bidding',\n",
       " 'billed',\n",
       " 'billing',\n",
       " 'blamed',\n",
       " 'bled',\n",
       " 'blessing',\n",
       " 'blighted',\n",
       " 'blocked',\n",
       " 'blurred',\n",
       " 'boarding',\n",
       " 'bolstered',\n",
       " 'bombarding',\n",
       " 'booked',\n",
       " 'booming',\n",
       " 'boosted',\n",
       " 'boosting',\n",
       " 'borrowed',\n",
       " 'borrowing',\n",
       " 'botched',\n",
       " 'bothered',\n",
       " 'bounced',\n",
       " 'bowed',\n",
       " 'breaking',\n",
       " 'breathed',\n",
       " 'breathtaking',\n",
       " 'breed',\n",
       " 'bribed',\n",
       " 'bribing',\n",
       " 'briefing',\n",
       " 'brightened',\n",
       " 'bring',\n",
       " 'bringing',\n",
       " 'broad-based',\n",
       " 'broadcasting',\n",
       " 'broadened',\n",
       " 'brokering',\n",
       " 'brushed',\n",
       " 'budding',\n",
       " 'building',\n",
       " 'bundling',\n",
       " 'buoyed',\n",
       " 'burned',\n",
       " 'buying',\n",
       " 'calculated',\n",
       " 'called',\n",
       " 'calling',\n",
       " 'campaigning',\n",
       " 'cancer-causing',\n",
       " 'capitalized',\n",
       " 'capped',\n",
       " 'captivating',\n",
       " 'cared',\n",
       " 'carried',\n",
       " 'carrying',\n",
       " 'cascading',\n",
       " 'casting',\n",
       " 'caused',\n",
       " 'causing',\n",
       " 'cautioned',\n",
       " 'ceiling',\n",
       " 'centralized',\n",
       " 'certified',\n",
       " 'chaired',\n",
       " 'challenging',\n",
       " 'championing',\n",
       " 'change-ringing',\n",
       " 'changed',\n",
       " 'changing',\n",
       " 'characterized',\n",
       " 'characterizing',\n",
       " 'charged',\n",
       " 'charging',\n",
       " 'chastised',\n",
       " 'cheating',\n",
       " 'checking',\n",
       " 'cheerleading',\n",
       " 'chilled',\n",
       " 'choosing',\n",
       " 'chopped',\n",
       " 'circulated',\n",
       " 'cited',\n",
       " 'citing',\n",
       " 'citizen-sparked',\n",
       " 'city-owned',\n",
       " 'claimed',\n",
       " 'claiming',\n",
       " 'clamped',\n",
       " 'clarified',\n",
       " 'clashed',\n",
       " 'classed',\n",
       " 'classified',\n",
       " 'cleaned',\n",
       " 'cleaner-burning',\n",
       " 'cleared',\n",
       " 'clearing',\n",
       " 'clicked',\n",
       " 'climbed',\n",
       " 'climbing',\n",
       " 'clipped',\n",
       " 'clobbered',\n",
       " 'closed',\n",
       " 'closing',\n",
       " 'clothing',\n",
       " 'clouding',\n",
       " 'cluttered',\n",
       " 'co-founded',\n",
       " 'coaching',\n",
       " 'coal-fired',\n",
       " 'coated',\n",
       " 'codified',\n",
       " 'collaborated',\n",
       " 'collapsed',\n",
       " 'collected',\n",
       " 'collecting',\n",
       " 'collective-bargaining',\n",
       " 'colored',\n",
       " 'combined',\n",
       " 'coming',\n",
       " 'commanded',\n",
       " 'commenting',\n",
       " 'committed',\n",
       " 'committing',\n",
       " 'compared',\n",
       " 'compelling',\n",
       " 'competed',\n",
       " 'competing',\n",
       " 'compiled',\n",
       " 'complained',\n",
       " 'complaining',\n",
       " 'completed',\n",
       " 'completing',\n",
       " 'complicated',\n",
       " 'composed',\n",
       " 'composting',\n",
       " 'compressed',\n",
       " 'computer-aided',\n",
       " 'computer-assisted',\n",
       " 'computer-generated',\n",
       " 'computerized',\n",
       " 'computing',\n",
       " 'conceding',\n",
       " 'concentrated',\n",
       " 'concentrating',\n",
       " 'concerned',\n",
       " 'concluded',\n",
       " 'condemned',\n",
       " 'condemning',\n",
       " 'conducted',\n",
       " 'conducting',\n",
       " 'confined',\n",
       " 'confirmed',\n",
       " 'confused',\n",
       " 'connected',\n",
       " 'consented',\n",
       " 'considered',\n",
       " 'considering',\n",
       " 'consisting',\n",
       " 'construed',\n",
       " 'consulting',\n",
       " 'contacted',\n",
       " 'contained',\n",
       " 'containing',\n",
       " 'contesting',\n",
       " 'continued',\n",
       " 'continuing',\n",
       " 'contracted',\n",
       " 'contributed',\n",
       " 'contributing',\n",
       " 'controlled',\n",
       " 'controlling',\n",
       " 'converted',\n",
       " 'converting',\n",
       " 'convicted',\n",
       " 'convinced',\n",
       " 'cooled',\n",
       " 'cooperating',\n",
       " 'copied',\n",
       " 'copying',\n",
       " 'corn-buying',\n",
       " 'corrected',\n",
       " 'correcting',\n",
       " 'cost-cutting',\n",
       " 'cost-sharing',\n",
       " 'counseling',\n",
       " 'counting',\n",
       " 'coupled',\n",
       " 'court-ordered',\n",
       " 'covered',\n",
       " 'covering',\n",
       " 'cranked',\n",
       " 'crashing',\n",
       " 'created',\n",
       " 'creating',\n",
       " 'credit-rating',\n",
       " 'crippled',\n",
       " 'criticized',\n",
       " 'crossed',\n",
       " 'crossing',\n",
       " 'crowded',\n",
       " 'cruising',\n",
       " 'crushed',\n",
       " 'crying',\n",
       " 'cultivated',\n",
       " 'curbed',\n",
       " 'curbing',\n",
       " 'curled',\n",
       " 'current-carrying',\n",
       " 'curtailed',\n",
       " 'cushioned',\n",
       " 'customized',\n",
       " 'cutting',\n",
       " 'damaged',\n",
       " 'damaging',\n",
       " 'dancing',\n",
       " 'darned',\n",
       " 'dashed',\n",
       " 'dating',\n",
       " 'dead-eyed',\n",
       " 'dealing',\n",
       " 'decided',\n",
       " 'declared',\n",
       " 'declaring',\n",
       " 'declined',\n",
       " 'declining',\n",
       " 'decorated',\n",
       " 'decried',\n",
       " 'deducting',\n",
       " 'deemed',\n",
       " 'defeated',\n",
       " 'defended',\n",
       " 'defined',\n",
       " 'defying',\n",
       " 'delayed',\n",
       " 'deliberating',\n",
       " 'delisted',\n",
       " 'delivered',\n",
       " 'delivering',\n",
       " 'demanding',\n",
       " 'demonstrating',\n",
       " 'denied',\n",
       " 'denouncing',\n",
       " 'denying',\n",
       " 'depended',\n",
       " 'depending',\n",
       " 'depleted',\n",
       " 'depressed',\n",
       " 'deprived',\n",
       " 'derived',\n",
       " 'descending',\n",
       " 'described',\n",
       " 'deserving',\n",
       " 'designated',\n",
       " 'designed',\n",
       " 'designing',\n",
       " 'desired',\n",
       " 'despised',\n",
       " 'detailed',\n",
       " 'deteriorated',\n",
       " 'deteriorating',\n",
       " 'determined',\n",
       " 'deterring',\n",
       " 'devastating',\n",
       " 'developed',\n",
       " 'developing',\n",
       " 'devised',\n",
       " 'devoted',\n",
       " 'devouring',\n",
       " 'diagnosed',\n",
       " 'died',\n",
       " 'diluted',\n",
       " 'diming',\n",
       " 'diminished',\n",
       " 'directed',\n",
       " 'directing',\n",
       " 'disaffected',\n",
       " 'disagreed',\n",
       " 'disappointed',\n",
       " 'disappointing',\n",
       " 'disapproved',\n",
       " 'discarded',\n",
       " 'disciplined',\n",
       " 'disclosed',\n",
       " 'disclosing',\n",
       " 'discontinued',\n",
       " 'discontinuing',\n",
       " 'discouraging',\n",
       " 'discovered',\n",
       " 'discussed',\n",
       " 'discussing',\n",
       " 'disembodied',\n",
       " 'dismayed',\n",
       " 'dismissed',\n",
       " 'disposed',\n",
       " 'disputed',\n",
       " 'disseminating',\n",
       " 'distinguished',\n",
       " 'distorted',\n",
       " 'distributed',\n",
       " 'disturbing',\n",
       " 'diversified',\n",
       " 'diversifying',\n",
       " 'divided',\n",
       " 'dividing',\n",
       " 'documented',\n",
       " 'doing',\n",
       " 'doling',\n",
       " 'dollar-denominated',\n",
       " 'dominated',\n",
       " 'dominating',\n",
       " 'doubled',\n",
       " 'doubted',\n",
       " 'downgraded',\n",
       " 'downgrading',\n",
       " 'drafted',\n",
       " 'drawing',\n",
       " 'dreamed',\n",
       " 'dressed',\n",
       " 'drifted',\n",
       " 'drinking',\n",
       " 'driving',\n",
       " 'drooled',\n",
       " 'dropped',\n",
       " 'dubbed',\n",
       " 'duckling',\n",
       " 'dumbfounded',\n",
       " 'dumped',\n",
       " 'during',\n",
       " 'dwindling',\n",
       " 'earned',\n",
       " 'earning',\n",
       " 'eased',\n",
       " 'easing',\n",
       " 'eating',\n",
       " 'echoed',\n",
       " 'edged',\n",
       " 'editing',\n",
       " 'educated',\n",
       " 'elected',\n",
       " 'eliminated',\n",
       " 'eliminating',\n",
       " 'embarrassing',\n",
       " 'embroiled',\n",
       " 'emerged',\n",
       " 'emerging',\n",
       " 'emphasized',\n",
       " 'employed',\n",
       " 'empowered',\n",
       " 'enabled',\n",
       " 'enabling',\n",
       " 'enacted',\n",
       " 'encircling',\n",
       " 'enclosed',\n",
       " 'encouraging',\n",
       " 'encroaching',\n",
       " 'ended',\n",
       " 'ending',\n",
       " 'endorsed',\n",
       " 'engaged',\n",
       " 'engaging',\n",
       " 'engineered',\n",
       " 'engineering',\n",
       " 'enhanced',\n",
       " 'enjoyed',\n",
       " 'enjoying',\n",
       " 'enlarged',\n",
       " 'enraged',\n",
       " 'ensnarled',\n",
       " 'entangled',\n",
       " 'entered',\n",
       " 'entering',\n",
       " 'entertaining',\n",
       " 'enticed',\n",
       " 'entitled',\n",
       " 'entrenched',\n",
       " 'entrusted',\n",
       " 'equaling',\n",
       " 'equipped',\n",
       " 'escalated',\n",
       " 'escaped',\n",
       " 'established',\n",
       " 'establishing',\n",
       " 'estimated',\n",
       " 'evaluated',\n",
       " 'evaluating',\n",
       " 'evaporated',\n",
       " 'evening',\n",
       " 'everything',\n",
       " 'evoking',\n",
       " 'evolved',\n",
       " 'exacerbated',\n",
       " 'examined',\n",
       " 'exceed',\n",
       " 'exceeded',\n",
       " 'exceeding',\n",
       " 'exchanging',\n",
       " 'excited',\n",
       " 'exciting',\n",
       " 'executed',\n",
       " 'executing',\n",
       " 'exercised',\n",
       " 'exerting',\n",
       " 'exhausted',\n",
       " 'exhibited',\n",
       " 'existed',\n",
       " 'existing',\n",
       " 'expanded',\n",
       " 'expanding',\n",
       " 'expected',\n",
       " 'expecting',\n",
       " 'expedited',\n",
       " 'expelled',\n",
       " 'experienced',\n",
       " 'experiencing',\n",
       " 'expired',\n",
       " 'explained',\n",
       " 'explaining',\n",
       " 'exploded',\n",
       " 'export-oriented',\n",
       " 'exposed',\n",
       " 'expressed',\n",
       " 'expressing',\n",
       " 'expunged',\n",
       " 'extended',\n",
       " 'extending',\n",
       " 'exuded',\n",
       " 'eyeing',\n",
       " 'fabled',\n",
       " 'faced',\n",
       " 'facing',\n",
       " 'factoring',\n",
       " 'faded',\n",
       " 'failed',\n",
       " 'failing',\n",
       " 'fainting',\n",
       " 'falling',\n",
       " 'faltered',\n",
       " 'famed',\n",
       " 'family-planning',\n",
       " 'fared',\n",
       " 'fashioned',\n",
       " 'fast-growing',\n",
       " 'fastest-growing',\n",
       " 'fattened',\n",
       " 'favored',\n",
       " 'fawning',\n",
       " 'feared',\n",
       " 'featured',\n",
       " 'featuring',\n",
       " 'fed',\n",
       " 'feed',\n",
       " 'feeling',\n",
       " 'fetching',\n",
       " 'fielded',\n",
       " 'fighting',\n",
       " 'filed',\n",
       " 'filing',\n",
       " 'filled',\n",
       " 'filling',\n",
       " 'finalized',\n",
       " 'financed',\n",
       " 'financing',\n",
       " 'finding',\n",
       " 'fined',\n",
       " 'finished',\n",
       " 'fired',\n",
       " 'firmed',\n",
       " 'fixed',\n",
       " 'fizzled',\n",
       " 'fled',\n",
       " 'fledgling',\n",
       " 'fleeting',\n",
       " 'flirted',\n",
       " 'floated',\n",
       " 'flooded',\n",
       " 'focused',\n",
       " 'focusing',\n",
       " 'folded',\n",
       " 'followed',\n",
       " 'following',\n",
       " 'forced',\n",
       " 'forcing',\n",
       " 'forecasting',\n",
       " 'foreign-led',\n",
       " 'formed',\n",
       " 'forthcoming',\n",
       " 'founded',\n",
       " 'foundering',\n",
       " 'fretted',\n",
       " 'frightened',\n",
       " 'frustrating',\n",
       " 'fueled',\n",
       " 'fueling',\n",
       " 'full-fledged',\n",
       " 'fuming',\n",
       " 'functioning',\n",
       " 'funded',\n",
       " 'funding',\n",
       " 'fundraising',\n",
       " 'futures-related',\n",
       " 'gained',\n",
       " 'gaining',\n",
       " 'galling',\n",
       " 'galvanized',\n",
       " 'gambling',\n",
       " 'gauging',\n",
       " 'generated',\n",
       " 'getting',\n",
       " 'giving',\n",
       " 'going',\n",
       " 'good-hearted',\n",
       " 'good-natured',\n",
       " 'gored',\n",
       " 'government-certified',\n",
       " 'government-funded',\n",
       " 'government-owned',\n",
       " 'graduated',\n",
       " 'granted',\n",
       " 'granting',\n",
       " 'greed',\n",
       " 'gripping',\n",
       " 'growing',\n",
       " 'guaranteed',\n",
       " 'guarding',\n",
       " 'guided',\n",
       " 'gut-wrenching',\n",
       " 'hailed',\n",
       " 'hailing',\n",
       " 'halted',\n",
       " 'hampered',\n",
       " 'handed',\n",
       " 'handled',\n",
       " 'handling',\n",
       " 'happened',\n",
       " 'happening',\n",
       " 'hard-charging',\n",
       " 'hard-drinking',\n",
       " 'hard-hitting',\n",
       " 'harmed',\n",
       " 'harped',\n",
       " 'harvested',\n",
       " 'hauled',\n",
       " 'hauling',\n",
       " 'having',\n",
       " 'headed',\n",
       " 'heading',\n",
       " 'headlined',\n",
       " 'healing',\n",
       " 'hearing',\n",
       " 'heated',\n",
       " 'heating',\n",
       " 'hedging',\n",
       " 'heightened',\n",
       " 'helped',\n",
       " 'helping',\n",
       " 'high-flying',\n",
       " 'high-minded',\n",
       " 'high-polluting',\n",
       " 'high-priced',\n",
       " 'high-rolling',\n",
       " 'high-speed',\n",
       " 'higher-salaried',\n",
       " 'highest-pitched',\n",
       " 'hired',\n",
       " 'hitting',\n",
       " 'holding',\n",
       " 'hoped',\n",
       " 'hosted',\n",
       " 'housing',\n",
       " 'hugging',\n",
       " 'hundred',\n",
       " 'hunted',\n",
       " 'hurting',\n",
       " 'identified',\n",
       " 'ignored',\n",
       " 'ignoring',\n",
       " 'impaired',\n",
       " 'impeding',\n",
       " 'impending',\n",
       " 'implemented',\n",
       " 'implied',\n",
       " 'imported',\n",
       " 'imposed',\n",
       " 'imposing',\n",
       " 'impressed',\n",
       " 'improved',\n",
       " 'improving',\n",
       " 'incentive-backed',\n",
       " 'inched',\n",
       " 'inching',\n",
       " 'included',\n",
       " 'including',\n",
       " 'incorporated',\n",
       " 'increased',\n",
       " 'increasing',\n",
       " 'incurred',\n",
       " 'indeed',\n",
       " 'index-related',\n",
       " 'indicated',\n",
       " 'indicating',\n",
       " 'indulging',\n",
       " 'industrialized',\n",
       " 'industry-supported',\n",
       " 'inflated',\n",
       " 'influenced',\n",
       " 'influencing',\n",
       " 'infringed',\n",
       " 'inherited',\n",
       " 'initialing',\n",
       " 'initiated',\n",
       " 'initiating',\n",
       " 'injecting',\n",
       " 'injuring',\n",
       " 'inkling',\n",
       " 'inquiring',\n",
       " 'inserted',\n",
       " 'insider-trading',\n",
       " 'insinuating',\n",
       " 'insisted',\n",
       " 'inspired',\n",
       " 'installed',\n",
       " 'installing',\n",
       " 'instituted',\n",
       " 'instructed',\n",
       " 'insured',\n",
       " 'integrated',\n",
       " 'intended',\n",
       " 'intentioned',\n",
       " 'interest-bearing',\n",
       " 'interested',\n",
       " 'interesting',\n",
       " 'interrogated',\n",
       " 'interviewed',\n",
       " 'intriguing',\n",
       " 'introduced',\n",
       " 'introducing',\n",
       " 'invented',\n",
       " 'inverted',\n",
       " 'invested',\n",
       " 'investigating',\n",
       " 'investing',\n",
       " 'inviting',\n",
       " 'involved',\n",
       " 'involving',\n",
       " 'issued',\n",
       " 'issuing',\n",
       " 'jeopardizing',\n",
       " 'joined',\n",
       " 'joining',\n",
       " 'judged',\n",
       " 'jumped',\n",
       " 'jumping',\n",
       " 'justified',\n",
       " 'justifying',\n",
       " 'keeping',\n",
       " 'kicked',\n",
       " 'kidnapping',\n",
       " 'killed',\n",
       " 'killing',\n",
       " 'knitted',\n",
       " 'knocked',\n",
       " 'labeled',\n",
       " 'labeling',\n",
       " 'labor-backed',\n",
       " 'lacked',\n",
       " 'lagging',\n",
       " 'land-idling',\n",
       " 'landing',\n",
       " 'lasted',\n",
       " 'lasting',\n",
       " 'lauded',\n",
       " 'laughing',\n",
       " 'launched',\n",
       " 'lawmaking',\n",
       " 'laying',\n",
       " 'leading',\n",
       " 'learned',\n",
       " 'learning',\n",
       " 'leasing',\n",
       " 'leaving',\n",
       " 'led',\n",
       " 'lending',\n",
       " 'lengthened',\n",
       " 'lessening',\n",
       " 'letter-writing',\n",
       " 'letting',\n",
       " 'leveling',\n",
       " 'leveraged',\n",
       " 'leveraging',\n",
       " 'licensed',\n",
       " 'licensing',\n",
       " 'lifted',\n",
       " ...]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " [w for w in wsj if re.search('(ed|ing)$', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['u',\n",
       " 'e',\n",
       " 'a',\n",
       " 'i',\n",
       " 'a',\n",
       " 'i',\n",
       " 'i',\n",
       " 'i',\n",
       " 'e',\n",
       " 'i',\n",
       " 'a',\n",
       " 'i',\n",
       " 'o',\n",
       " 'i',\n",
       " 'o',\n",
       " 'u']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = 'supercalifragilisticexpialidocious'\n",
    "re.findall(r'[aeiou]', word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(re.findall(r'[aeiou]', word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " \"''\",\n",
       " \"'30s\",\n",
       " \"'40s\",\n",
       " \"'50s\",\n",
       " \"'80s\",\n",
       " \"'82\",\n",
       " \"'86\",\n",
       " \"'S\",\n",
       " \"'d\",\n",
       " \"'ll\",\n",
       " \"'m\",\n",
       " \"'re\",\n",
       " \"'s\",\n",
       " \"'ve\",\n",
       " '*',\n",
       " '*-1',\n",
       " '*-10',\n",
       " '*-100',\n",
       " '*-101',\n",
       " '*-102',\n",
       " '*-103',\n",
       " '*-104',\n",
       " '*-105',\n",
       " '*-106',\n",
       " '*-107',\n",
       " '*-108',\n",
       " '*-109',\n",
       " '*-11',\n",
       " '*-110',\n",
       " '*-111',\n",
       " '*-112',\n",
       " '*-113',\n",
       " '*-114',\n",
       " '*-115',\n",
       " '*-116',\n",
       " '*-117',\n",
       " '*-118',\n",
       " '*-119',\n",
       " '*-12',\n",
       " '*-120',\n",
       " '*-121',\n",
       " '*-122',\n",
       " '*-123',\n",
       " '*-124',\n",
       " '*-125',\n",
       " '*-126',\n",
       " '*-127',\n",
       " '*-128',\n",
       " '*-129',\n",
       " '*-13',\n",
       " '*-130',\n",
       " '*-131',\n",
       " '*-132',\n",
       " '*-133',\n",
       " '*-134',\n",
       " '*-135',\n",
       " '*-136',\n",
       " '*-137',\n",
       " '*-138',\n",
       " '*-139',\n",
       " '*-14',\n",
       " '*-140',\n",
       " '*-141',\n",
       " '*-142',\n",
       " '*-144',\n",
       " '*-145',\n",
       " '*-146',\n",
       " '*-147',\n",
       " '*-149',\n",
       " '*-15',\n",
       " '*-150',\n",
       " '*-151',\n",
       " '*-152',\n",
       " '*-153',\n",
       " '*-154',\n",
       " '*-155',\n",
       " '*-156',\n",
       " '*-157',\n",
       " '*-158',\n",
       " '*-159',\n",
       " '*-16',\n",
       " '*-160',\n",
       " '*-161',\n",
       " '*-162',\n",
       " '*-163',\n",
       " '*-164',\n",
       " '*-165',\n",
       " '*-166',\n",
       " '*-17',\n",
       " '*-18',\n",
       " '*-19',\n",
       " '*-2',\n",
       " '*-20',\n",
       " '*-21',\n",
       " '*-22',\n",
       " '*-23',\n",
       " '*-24',\n",
       " '*-25',\n",
       " '*-26',\n",
       " '*-27',\n",
       " '*-28',\n",
       " '*-29',\n",
       " '*-3',\n",
       " '*-30',\n",
       " '*-31',\n",
       " '*-32',\n",
       " '*-33',\n",
       " '*-34',\n",
       " '*-35',\n",
       " '*-36',\n",
       " '*-37',\n",
       " '*-38',\n",
       " '*-39',\n",
       " '*-4',\n",
       " '*-40',\n",
       " '*-41',\n",
       " '*-42',\n",
       " '*-43',\n",
       " '*-44',\n",
       " '*-45',\n",
       " '*-46',\n",
       " '*-47',\n",
       " '*-48',\n",
       " '*-49',\n",
       " '*-5',\n",
       " '*-50',\n",
       " '*-51',\n",
       " '*-52',\n",
       " '*-53',\n",
       " '*-54',\n",
       " '*-55',\n",
       " '*-56',\n",
       " '*-57',\n",
       " '*-58',\n",
       " '*-59',\n",
       " '*-6',\n",
       " '*-60',\n",
       " '*-61',\n",
       " '*-62',\n",
       " '*-63',\n",
       " '*-64',\n",
       " '*-66',\n",
       " '*-67',\n",
       " '*-68',\n",
       " '*-69',\n",
       " '*-7',\n",
       " '*-70',\n",
       " '*-71',\n",
       " '*-72',\n",
       " '*-73',\n",
       " '*-74',\n",
       " '*-75',\n",
       " '*-76',\n",
       " '*-77',\n",
       " '*-78',\n",
       " '*-79',\n",
       " '*-8',\n",
       " '*-80',\n",
       " '*-81',\n",
       " '*-82',\n",
       " '*-83',\n",
       " '*-84',\n",
       " '*-85',\n",
       " '*-86',\n",
       " '*-87',\n",
       " '*-88',\n",
       " '*-89',\n",
       " '*-9',\n",
       " '*-90',\n",
       " '*-91',\n",
       " '*-92',\n",
       " '*-93',\n",
       " '*-94',\n",
       " '*-95',\n",
       " '*-96',\n",
       " '*-97',\n",
       " '*-98',\n",
       " '*-99',\n",
       " '*?*',\n",
       " '*EXP*-1',\n",
       " '*EXP*-2',\n",
       " '*EXP*-3',\n",
       " '*ICH*-1',\n",
       " '*ICH*-2',\n",
       " '*ICH*-3',\n",
       " '*ICH*-4',\n",
       " '*NOT*',\n",
       " '*PPA*-1',\n",
       " '*PPA*-2',\n",
       " '*PPA*-3',\n",
       " '*RNR*-1',\n",
       " '*RNR*-2',\n",
       " '*RNR*-4',\n",
       " '*T*-1',\n",
       " '*T*-10',\n",
       " '*T*-100',\n",
       " '*T*-101',\n",
       " '*T*-102',\n",
       " '*T*-103',\n",
       " '*T*-104',\n",
       " '*T*-105',\n",
       " '*T*-106',\n",
       " '*T*-107',\n",
       " '*T*-108',\n",
       " '*T*-109',\n",
       " '*T*-11',\n",
       " '*T*-110',\n",
       " '*T*-111',\n",
       " '*T*-112',\n",
       " '*T*-113',\n",
       " '*T*-114',\n",
       " '*T*-115',\n",
       " '*T*-116',\n",
       " '*T*-117',\n",
       " '*T*-118',\n",
       " '*T*-119',\n",
       " '*T*-12',\n",
       " '*T*-120',\n",
       " '*T*-121',\n",
       " '*T*-122',\n",
       " '*T*-123',\n",
       " '*T*-124',\n",
       " '*T*-125',\n",
       " '*T*-126',\n",
       " '*T*-127',\n",
       " '*T*-128',\n",
       " '*T*-129',\n",
       " '*T*-13',\n",
       " '*T*-130',\n",
       " '*T*-131',\n",
       " '*T*-132',\n",
       " '*T*-133',\n",
       " '*T*-134',\n",
       " '*T*-135',\n",
       " '*T*-136',\n",
       " '*T*-137',\n",
       " '*T*-138',\n",
       " '*T*-139',\n",
       " '*T*-14',\n",
       " '*T*-140',\n",
       " '*T*-141',\n",
       " '*T*-142',\n",
       " '*T*-143',\n",
       " '*T*-144',\n",
       " '*T*-145',\n",
       " '*T*-146',\n",
       " '*T*-147',\n",
       " '*T*-148',\n",
       " '*T*-149',\n",
       " '*T*-15',\n",
       " '*T*-150',\n",
       " '*T*-151',\n",
       " '*T*-152',\n",
       " '*T*-153',\n",
       " '*T*-154',\n",
       " '*T*-155',\n",
       " '*T*-156',\n",
       " '*T*-157',\n",
       " '*T*-158',\n",
       " '*T*-159',\n",
       " '*T*-16',\n",
       " '*T*-160',\n",
       " '*T*-161',\n",
       " '*T*-162',\n",
       " '*T*-163',\n",
       " '*T*-164',\n",
       " '*T*-165',\n",
       " '*T*-166',\n",
       " '*T*-167',\n",
       " '*T*-168',\n",
       " '*T*-169',\n",
       " '*T*-17',\n",
       " '*T*-170',\n",
       " '*T*-171',\n",
       " '*T*-172',\n",
       " '*T*-173',\n",
       " '*T*-174',\n",
       " '*T*-175',\n",
       " '*T*-176',\n",
       " '*T*-177',\n",
       " '*T*-178',\n",
       " '*T*-179',\n",
       " '*T*-18',\n",
       " '*T*-180',\n",
       " '*T*-181',\n",
       " '*T*-182',\n",
       " '*T*-183',\n",
       " '*T*-184',\n",
       " '*T*-185',\n",
       " '*T*-186',\n",
       " '*T*-187',\n",
       " '*T*-188',\n",
       " '*T*-189',\n",
       " '*T*-19',\n",
       " '*T*-190',\n",
       " '*T*-191',\n",
       " '*T*-192',\n",
       " '*T*-193',\n",
       " '*T*-194',\n",
       " '*T*-195',\n",
       " '*T*-196',\n",
       " '*T*-197',\n",
       " '*T*-198',\n",
       " '*T*-199',\n",
       " '*T*-2',\n",
       " '*T*-20',\n",
       " '*T*-200',\n",
       " '*T*-201',\n",
       " '*T*-202',\n",
       " '*T*-203',\n",
       " '*T*-204',\n",
       " '*T*-205',\n",
       " '*T*-206',\n",
       " '*T*-207',\n",
       " '*T*-208',\n",
       " '*T*-21',\n",
       " '*T*-210',\n",
       " '*T*-211',\n",
       " '*T*-212',\n",
       " '*T*-213',\n",
       " '*T*-214',\n",
       " '*T*-215',\n",
       " '*T*-216',\n",
       " '*T*-217',\n",
       " '*T*-218',\n",
       " '*T*-219',\n",
       " '*T*-22',\n",
       " '*T*-220',\n",
       " '*T*-221',\n",
       " '*T*-222',\n",
       " '*T*-223',\n",
       " '*T*-224',\n",
       " '*T*-225',\n",
       " '*T*-226',\n",
       " '*T*-227',\n",
       " '*T*-228',\n",
       " '*T*-229',\n",
       " '*T*-23',\n",
       " '*T*-230',\n",
       " '*T*-231',\n",
       " '*T*-232',\n",
       " '*T*-233',\n",
       " '*T*-234',\n",
       " '*T*-235',\n",
       " '*T*-236',\n",
       " '*T*-237',\n",
       " '*T*-238',\n",
       " '*T*-239',\n",
       " '*T*-24',\n",
       " '*T*-240',\n",
       " '*T*-241',\n",
       " '*T*-242',\n",
       " '*T*-243',\n",
       " '*T*-244',\n",
       " '*T*-245',\n",
       " '*T*-246',\n",
       " '*T*-247',\n",
       " '*T*-248',\n",
       " '*T*-249',\n",
       " '*T*-25',\n",
       " '*T*-250',\n",
       " '*T*-251',\n",
       " '*T*-252',\n",
       " '*T*-253',\n",
       " '*T*-254',\n",
       " '*T*-255',\n",
       " '*T*-256',\n",
       " '*T*-257',\n",
       " '*T*-258',\n",
       " '*T*-259',\n",
       " '*T*-26',\n",
       " '*T*-260',\n",
       " '*T*-27',\n",
       " '*T*-28',\n",
       " '*T*-29',\n",
       " '*T*-3',\n",
       " '*T*-30',\n",
       " '*T*-31',\n",
       " '*T*-32',\n",
       " '*T*-33',\n",
       " '*T*-34',\n",
       " '*T*-35',\n",
       " '*T*-36',\n",
       " '*T*-37',\n",
       " '*T*-38',\n",
       " '*T*-39',\n",
       " '*T*-4',\n",
       " '*T*-40',\n",
       " '*T*-41',\n",
       " '*T*-42',\n",
       " '*T*-43',\n",
       " '*T*-44',\n",
       " '*T*-45',\n",
       " '*T*-46',\n",
       " '*T*-47',\n",
       " '*T*-48',\n",
       " '*T*-49',\n",
       " '*T*-5',\n",
       " '*T*-50',\n",
       " '*T*-51',\n",
       " '*T*-52',\n",
       " '*T*-53',\n",
       " '*T*-54',\n",
       " '*T*-55',\n",
       " '*T*-56',\n",
       " '*T*-57',\n",
       " '*T*-58',\n",
       " '*T*-59',\n",
       " '*T*-6',\n",
       " '*T*-60',\n",
       " '*T*-61',\n",
       " '*T*-62',\n",
       " '*T*-63',\n",
       " '*T*-64',\n",
       " '*T*-65',\n",
       " '*T*-66',\n",
       " '*T*-67',\n",
       " '*T*-68',\n",
       " '*T*-69',\n",
       " '*T*-7',\n",
       " '*T*-70',\n",
       " '*T*-71',\n",
       " '*T*-72',\n",
       " '*T*-73',\n",
       " '*T*-74',\n",
       " '*T*-75',\n",
       " '*T*-76',\n",
       " '*T*-77',\n",
       " '*T*-78',\n",
       " '*T*-79',\n",
       " '*T*-8',\n",
       " '*T*-80',\n",
       " '*T*-81',\n",
       " '*T*-82',\n",
       " '*T*-83',\n",
       " '*T*-84',\n",
       " '*T*-85',\n",
       " '*T*-86',\n",
       " '*T*-87',\n",
       " '*T*-88',\n",
       " '*T*-89',\n",
       " '*T*-9',\n",
       " '*T*-90',\n",
       " '*T*-91',\n",
       " '*T*-92',\n",
       " '*T*-93',\n",
       " '*T*-94',\n",
       " '*T*-95',\n",
       " '*T*-96',\n",
       " '*T*-97',\n",
       " '*T*-98',\n",
       " '*T*-99',\n",
       " '*U*',\n",
       " ',',\n",
       " '-',\n",
       " '--',\n",
       " '-LCB-',\n",
       " '-LRB-',\n",
       " '-RCB-',\n",
       " '-RRB-',\n",
       " '.',\n",
       " '...',\n",
       " '0',\n",
       " '0.0085',\n",
       " '0.05',\n",
       " '0.1',\n",
       " '0.16',\n",
       " '0.2',\n",
       " '0.25',\n",
       " '0.28',\n",
       " '0.3',\n",
       " '0.4',\n",
       " '0.5',\n",
       " '0.50',\n",
       " '0.54',\n",
       " '0.56',\n",
       " '0.60',\n",
       " '0.7',\n",
       " '0.82',\n",
       " '0.84',\n",
       " '0.9',\n",
       " '0.95',\n",
       " '0.99',\n",
       " '1',\n",
       " '1,000',\n",
       " '1,050,000',\n",
       " '1,100',\n",
       " '1,200',\n",
       " '1,298',\n",
       " '1,400',\n",
       " '1,460',\n",
       " '1,500',\n",
       " '1,570',\n",
       " '1,620',\n",
       " '1,880',\n",
       " '1.01',\n",
       " '1.1',\n",
       " '1.125',\n",
       " '1.14',\n",
       " '1.1650',\n",
       " '1.17',\n",
       " '1.18',\n",
       " '1.19',\n",
       " '1.2',\n",
       " '1.20',\n",
       " '1.24',\n",
       " '1.25',\n",
       " '1.26',\n",
       " '1.28',\n",
       " '1.35',\n",
       " '1.39',\n",
       " '1.4',\n",
       " '1.457',\n",
       " '1.46',\n",
       " '1.49',\n",
       " '1.5',\n",
       " '1.50',\n",
       " '1.55',\n",
       " '1.56',\n",
       " '1.5755',\n",
       " '1.5805',\n",
       " '1.6',\n",
       " '1.61',\n",
       " '1.637',\n",
       " '1.64',\n",
       " '1.65',\n",
       " '1.7',\n",
       " '1.75',\n",
       " '1.76',\n",
       " '1.8',\n",
       " '1.82',\n",
       " '1.8415',\n",
       " '1.85',\n",
       " '1.8500',\n",
       " '1.9',\n",
       " '1.916',\n",
       " '1.92',\n",
       " '10',\n",
       " '10,000',\n",
       " '10-day',\n",
       " '10-lap',\n",
       " '10-year',\n",
       " '10.19',\n",
       " '10.2',\n",
       " '10.5',\n",
       " '100',\n",
       " '100,000',\n",
       " '100,980',\n",
       " '100-megabyte',\n",
       " '100-share',\n",
       " '101',\n",
       " '102',\n",
       " '103',\n",
       " '105',\n",
       " '106',\n",
       " '107',\n",
       " '107.03',\n",
       " '107.9',\n",
       " '108',\n",
       " '109.73',\n",
       " '10th',\n",
       " '11',\n",
       " '11,000',\n",
       " '11,390,000',\n",
       " '11,762',\n",
       " '11-month-old',\n",
       " '11.10',\n",
       " '11.5',\n",
       " '11.57',\n",
       " '11.6',\n",
       " '11.72',\n",
       " '11.95',\n",
       " '110',\n",
       " '111',\n",
       " '112.9',\n",
       " '113.2',\n",
       " '114',\n",
       " '115',\n",
       " '116.3',\n",
       " '116.4',\n",
       " '116.7',\n",
       " '116.9',\n",
       " '118',\n",
       " '118.6',\n",
       " '119',\n",
       " '11\\\\/16',\n",
       " '11th',\n",
       " '12',\n",
       " '12,252',\n",
       " '12-member',\n",
       " '12-point',\n",
       " '12-year',\n",
       " '12.09',\n",
       " '12.5',\n",
       " '12.52',\n",
       " '12.68',\n",
       " '12.7',\n",
       " '12.82',\n",
       " '12.97',\n",
       " '120',\n",
       " '120,000',\n",
       " '120-a-share',\n",
       " '120.7',\n",
       " '1206.26',\n",
       " '121.6',\n",
       " '125',\n",
       " '126,000',\n",
       " '126.1',\n",
       " '126.15',\n",
       " '127.03',\n",
       " '128',\n",
       " '129.91',\n",
       " '12\\\\/32',\n",
       " '13',\n",
       " '13,056',\n",
       " '13.1',\n",
       " '13.15',\n",
       " '13.5',\n",
       " '13.50',\n",
       " '13.625',\n",
       " '13.65',\n",
       " '13.73',\n",
       " '13.8',\n",
       " '13.90',\n",
       " '130',\n",
       " '130.6',\n",
       " '130.7',\n",
       " '131.01',\n",
       " '132',\n",
       " '132,000',\n",
       " '132.9',\n",
       " '133',\n",
       " '133.7',\n",
       " '133.8',\n",
       " '135',\n",
       " '138',\n",
       " '139',\n",
       " '13\\\\/16',\n",
       " '14',\n",
       " '14,821',\n",
       " '14-hour',\n",
       " '14.',\n",
       " '14.00',\n",
       " '14.13',\n",
       " '14.26',\n",
       " '14.28',\n",
       " '14.43',\n",
       " '14.5',\n",
       " '14.53',\n",
       " '14.54',\n",
       " '14.6',\n",
       " '14.75',\n",
       " '14.99',\n",
       " '140',\n",
       " '141.9',\n",
       " '142.84',\n",
       " '142.85',\n",
       " '143.08',\n",
       " '143.80',\n",
       " '143.93',\n",
       " '144',\n",
       " '145',\n",
       " '148',\n",
       " '148.9',\n",
       " '149',\n",
       " '149.9',\n",
       " '14\\\\/32',\n",
       " '15',\n",
       " '15,000',\n",
       " '15-day',\n",
       " '15.5',\n",
       " '150',\n",
       " '150,000',\n",
       " '150-point',\n",
       " '150.00',\n",
       " '152,000',\n",
       " '153.3',\n",
       " '154,240,000',\n",
       " '154.2',\n",
       " '155',\n",
       " '158,666',\n",
       " '16',\n",
       " '16,000',\n",
       " '16,072',\n",
       " '16.05',\n",
       " '16.09',\n",
       " '16.125',\n",
       " '16.2',\n",
       " '16.5',\n",
       " '16.68',\n",
       " '16.7',\n",
       " '16.9',\n",
       " '160',\n",
       " '1614',\n",
       " '1637',\n",
       " '169.9',\n",
       " '16\\\\/32',\n",
       " '17',\n",
       " '17-year-old',\n",
       " '17.3',\n",
       " '17.4',\n",
       " '17.5',\n",
       " '17.95',\n",
       " '170',\n",
       " '170,000',\n",
       " '170,262',\n",
       " '1738.1',\n",
       " '175',\n",
       " '176',\n",
       " '176.1',\n",
       " '177',\n",
       " '1787',\n",
       " '179',\n",
       " '18',\n",
       " '18,000',\n",
       " '18,444',\n",
       " '18-a-share',\n",
       " '18-year-old',\n",
       " '18.3',\n",
       " '18.6',\n",
       " '18.95',\n",
       " '180',\n",
       " '184',\n",
       " '185.9',\n",
       " '187',\n",
       " '188',\n",
       " '188.84',\n",
       " '19',\n",
       " '19-month-old',\n",
       " '19.3',\n",
       " '19.50',\n",
       " '19.6',\n",
       " '19.94',\n",
       " '19.95',\n",
       " '190',\n",
       " '190-point',\n",
       " '1901',\n",
       " '1903',\n",
       " '191.9',\n",
       " '1917',\n",
       " '1920s',\n",
       " '1925',\n",
       " '1928-33',\n",
       " '1929',\n",
       " '1933',\n",
       " '1934',\n",
       " '1937-40',\n",
       " '1940s',\n",
       " '1948',\n",
       " '195',\n",
       " '1950s',\n",
       " '1953',\n",
       " '1955',\n",
       " '1956',\n",
       " '1960s',\n",
       " '1961',\n",
       " '1965',\n",
       " '1966',\n",
       " '1967',\n",
       " '1968',\n",
       " '1969',\n",
       " '1970',\n",
       " '1970s',\n",
       " '1971',\n",
       " '1972',\n",
       " '1973',\n",
       " '1973-75',\n",
       " '1975',\n",
       " '1976',\n",
       " '1977',\n",
       " '1979',\n",
       " '198',\n",
       " '1980',\n",
       " '1980s',\n",
       " '1981',\n",
       " '1982',\n",
       " '1983',\n",
       " '1983-85',\n",
       " '1984',\n",
       " '1985',\n",
       " '1986',\n",
       " '1986-87',\n",
       " '1987',\n",
       " '1987-88',\n",
       " '1988',\n",
       " '1988-89',\n",
       " '1989',\n",
       " '1989-90',\n",
       " '1990',\n",
       " '1990-91',\n",
       " '1990s',\n",
       " '1991',\n",
       " '1991-1999',\n",
       " '1991-2000',\n",
       " '1992',\n",
       " '1992-1999',\n",
       " '1993',\n",
       " '1994',\n",
       " '1995',\n",
       " '1996',\n",
       " '1997',\n",
       " '1998',\n",
       " '1999',\n",
       " '1:30',\n",
       " '1\\\\/10th',\n",
       " '1\\\\/2',\n",
       " '1\\\\/4',\n",
       " '1\\\\/8',\n",
       " '1st',\n",
       " '2',\n",
       " '2,000',\n",
       " '2,050-passenger',\n",
       " '2,099',\n",
       " '2,303,328',\n",
       " '2,410',\n",
       " '2,500',\n",
       " '2,700',\n",
       " '2-3',\n",
       " '2-8',\n",
       " '2.07',\n",
       " '2.1',\n",
       " '2.15',\n",
       " '2.19',\n",
       " '2.2',\n",
       " '2.25',\n",
       " '2.29',\n",
       " '2.3',\n",
       " '2.30',\n",
       " '2.35',\n",
       " '2.375',\n",
       " '2.4',\n",
       " '2.42',\n",
       " '2.44',\n",
       " '2.46',\n",
       " '2.47',\n",
       " '2.5',\n",
       " '2.50',\n",
       " '2.6',\n",
       " '2.62',\n",
       " '2.65',\n",
       " '2.7',\n",
       " '2.75',\n",
       " '2.8',\n",
       " '2.80',\n",
       " '2.87',\n",
       " '2.875',\n",
       " '2.9',\n",
       " '2.95',\n",
       " '20',\n",
       " '20,000',\n",
       " '20-point',\n",
       " '20-stock',\n",
       " '20.07',\n",
       " '20.5',\n",
       " '200',\n",
       " '200,000',\n",
       " '2000',\n",
       " '2003\\\\/2007',\n",
       " '2005',\n",
       " '2009',\n",
       " '2017',\n",
       " '2019',\n",
       " '2029',\n",
       " '203',\n",
       " '20s',\n",
       " '21',\n",
       " '21,000',\n",
       " '21-month',\n",
       " '21.1',\n",
       " '21.9',\n",
       " '210',\n",
       " '210,000',\n",
       " '212',\n",
       " '214',\n",
       " '2141.7',\n",
       " '2160.1',\n",
       " '2163.2',\n",
       " '22',\n",
       " '22.75',\n",
       " '220',\n",
       " '220.45',\n",
       " '221.4',\n",
       " '225',\n",
       " '225,000',\n",
       " '225.6',\n",
       " '226,570,380',\n",
       " '227',\n",
       " '228',\n",
       " '22\\\\/32',\n",
       " '23',\n",
       " '23,000',\n",
       " '23,403',\n",
       " '23.25',\n",
       " '23.4',\n",
       " '23.5',\n",
       " '23.72',\n",
       " '230-215',\n",
       " '234.4',\n",
       " '235',\n",
       " '236.74',\n",
       " '236.79',\n",
       " '237-seat',\n",
       " '238,000-circulation',\n",
       " '24',\n",
       " '24,000',\n",
       " '24.95',\n",
       " '240',\n",
       " '240,000',\n",
       " '240-page',\n",
       " '241',\n",
       " '244,000',\n",
       " '245',\n",
       " '25',\n",
       " '25,000',\n",
       " '25-year-old',\n",
       " '25.50',\n",
       " '25.6',\n",
       " '250',\n",
       " '250,000',\n",
       " '251.2',\n",
       " '257',\n",
       " '26',\n",
       " '26,000',\n",
       " '26,956',\n",
       " '26.2',\n",
       " '26.5',\n",
       " '26.8',\n",
       " '260',\n",
       " '263.07',\n",
       " '2645.90',\n",
       " '266',\n",
       " '2691.19',\n",
       " '27',\n",
       " '27-year',\n",
       " '27.1',\n",
       " '27.4',\n",
       " '270',\n",
       " '271,124',\n",
       " '271-147',\n",
       " '273.5',\n",
       " '274',\n",
       " '275',\n",
       " '278.7',\n",
       " '28',\n",
       " '28.25',\n",
       " '28.36',\n",
       " '28.4',\n",
       " '28.5',\n",
       " '28.53',\n",
       " '28.6',\n",
       " '280',\n",
       " '282',\n",
       " '286',\n",
       " '29',\n",
       " '29.3',\n",
       " '29.4',\n",
       " '29.9',\n",
       " '292.32',\n",
       " '295',\n",
       " '29year',\n",
       " '2\\\\/32',\n",
       " '3',\n",
       " '3,040,000',\n",
       " '3,250,000',\n",
       " '3,288,453',\n",
       " '3,500',\n",
       " '3,600',\n",
       " '3-4',\n",
       " '3.01',\n",
       " '3.04',\n",
       " '3.1',\n",
       " '3.16',\n",
       " '3.18',\n",
       " '3.19',\n",
       " '3.2',\n",
       " '3.20',\n",
       " '3.23',\n",
       " '3.253',\n",
       " '3.28',\n",
       " '3.3',\n",
       " '3.35',\n",
       " '3.375',\n",
       " '3.4',\n",
       " '3.42',\n",
       " '3.43',\n",
       " '3.5',\n",
       " '3.55',\n",
       " '3.6',\n",
       " '3.61',\n",
       " '3.625',\n",
       " '3.7',\n",
       " '3.75',\n",
       " '3.8',\n",
       " '3.80',\n",
       " ...]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wsj = sorted(set(nltk.corpus.treebank.words()))\n",
    "wsj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = nltk.FreqDist(vs for word in wsj\n",
    "                   for vs in re.findall(r'[aeiou]{2,}', word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('io', 549),\n",
       " ('ea', 476),\n",
       " ('ie', 331),\n",
       " ('ou', 329),\n",
       " ('ai', 261),\n",
       " ('ia', 253),\n",
       " ('ee', 217),\n",
       " ('oo', 174),\n",
       " ('ua', 109),\n",
       " ('au', 106),\n",
       " ('ue', 105),\n",
       " ('ui', 95)]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd.most_common(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['31']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'\\d{4}-\\d{2}-(\\d{2})', '2009-12-31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "regexp = r'^[AEIOUaeiou]+|[AEIOUaeiou]+$|[^AEIOUaeiou]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unvrsl Dclrtn of Hmn Rghts Prmble Whrs rcgntn of the inhrnt dgnty and\n",
      "of the eql and inlnble rghts of all mmbrs of the hmn fmly is the fndtn\n",
      "of frdm , jstce and pce in the wrld , Whrs dsrgrd and cntmpt fr hmn\n",
      "rghts hve rsltd in brbrs acts whch hve outrgd the cnscnce of mnknd ,\n",
      "and the advnt of a wrld in whch hmn bngs shll enjy frdm of spch and\n"
     ]
    }
   ],
   "source": [
    "def compress(word):\n",
    "    pieces = re.findall(regexp, word)\n",
    "    return ''.join(pieces)\n",
    "english_udhr = nltk.corpus.udhr.words('English-Latin1')\n",
    "print(nltk.tokenwrap(compress(w) for w in english_udhr[:75]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotokas_words = nltk.corpus.toolbox.words('rotokas.dic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvs = [cv for w in rotokas_words for cv in re.findall(r'[ptksvr][aeiou]', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a   e   i   o   u \n",
      "k 418 148  94 420 173 \n",
      "p  83  31 105  34  51 \n",
      "r 187  63  84  89  79 \n",
      "s   0   0 100   2   1 \n",
      "t  47   8   0 148  37 \n",
      "v  93  27 105  48  49 \n"
     ]
    }
   ],
   "source": [
    "cfd = nltk.ConditionalFreqDist(cvs)\n",
    "cfd.tabulate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examinando as linhas de s e t , vemos que estão em \"distribuição complementar\" parcial, o que é uma evidência de que não são fonemas distintos na língua. Assim, poderíamos concebivelmente retirar s do alfabeto Rotokas e simplesmente ter uma regra de pronúncia de que a letra t é pronunciada s quando seguida por i ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kaapo',\n",
       " 'kaapopato',\n",
       " 'kaipori',\n",
       " 'kaiporipie',\n",
       " 'kaiporivira',\n",
       " 'kapo',\n",
       " 'kapoa',\n",
       " 'kapokao',\n",
       " 'kapokapo',\n",
       " 'kapokapo',\n",
       " 'kapokapoa',\n",
       " 'kapokapoa',\n",
       " 'kapokapora',\n",
       " 'kapokapora',\n",
       " 'kapokaporo',\n",
       " 'kapokaporo',\n",
       " 'kapokari',\n",
       " 'kapokarito',\n",
       " 'kapokoa',\n",
       " 'kapoo',\n",
       " 'kapooto',\n",
       " 'kapoovira',\n",
       " 'kapopaa',\n",
       " 'kaporo',\n",
       " 'kaporo',\n",
       " 'kaporopa',\n",
       " 'kaporoto',\n",
       " 'kapoto',\n",
       " 'karokaropo',\n",
       " 'karopo',\n",
       " 'kepo',\n",
       " 'kepoi',\n",
       " 'keposi',\n",
       " 'kepoto']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_word_pairs = [(cv, w) for w in rotokas_words\n",
    "                for cv in re.findall(r'[ptksvr][aeiou]', w)]\n",
    "cv_index = nltk.Index (cv_word_pairs)# nltk.Index () , converte isso em um índice útil.\n",
    "cv_index [ 'po' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kasuari']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_index [ 'su' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(word):\n",
    "    for suffix in ['ing', 'ly', 'ed', 'ious', 'ies', 'ive', 'es', 's', 'ment']:\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "    return word  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ing']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'^.*(ing|ly|ed|ious|ies|ive|es|s|ment)$', 'processing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['processing']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'^.*(?:ing|ly|ed|ious|ies|ive|es|s|ment)$', 'processing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['processing']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'^.*(?:ing|ly|ed|ious|ies|ive|es|s|ment)$', 'processing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('process', 'ing')]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'^(.*)(ing|ly|ed|ious|ies|ive|es|s|ment)$', 'processing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A expressão regular encontrou incorretamente um sufixo -s em vez de um sufixo -es . Isso demonstra outra sutileza: o operador estrela é \"ganancioso\" e a parte . * Da expressão tenta consumir o máximo possível da entrada. Se usarmos a versão \"não gananciosa\" do operador estrela, escrita *?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('processe', 's')]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'^(.*)(ing|ly|ed|ious|ies|ive|es|s|ment)$', 'processes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('process', 'es')]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'^(.*?)(ing|ly|ed|ious|ies|ive|es|s|ment)$', 'processes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('language', '')]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'^(.*?)(ing|ly|ed|ious|ies|ive|es|s|ment)?$', 'language')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DENNIS',\n",
       " ':',\n",
       " 'Listen',\n",
       " ',',\n",
       " 'strange',\n",
       " 'women',\n",
       " 'ly',\n",
       " 'in',\n",
       " 'pond',\n",
       " 'distribut',\n",
       " 'sword',\n",
       " 'i',\n",
       " 'no',\n",
       " 'basi',\n",
       " 'for',\n",
       " 'a',\n",
       " 'system',\n",
       " 'of',\n",
       " 'govern',\n",
       " '.',\n",
       " 'Supreme',\n",
       " 'execut',\n",
       " 'power',\n",
       " 'deriv',\n",
       " 'from',\n",
       " 'a',\n",
       " 'mandate',\n",
       " 'from',\n",
       " 'the',\n",
       " 'mass',\n",
       " ',',\n",
       " 'not',\n",
       " 'from',\n",
       " 'some',\n",
       " 'farcical',\n",
       " 'aquatic',\n",
       " 'ceremony',\n",
       " '.']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stem(word):\n",
    "    regexp = r'^(.*?)(ing|ly|ed|ious|ies|ive|es|s|ment)?$'\n",
    "    stem, suffix = re.findall(regexp, word)[0]\n",
    "    return stem\n",
    "raw = \"\"\"DENNIS: Listen, strange women lying in ponds distributing swords\n",
    " is no basis for a system of government.  Supreme executive power derives from\n",
    " a mandate from the masses, not from some farcical aquatic ceremony.\"\"\"\n",
    "tokens = word_tokenize(raw)\n",
    "[stem(t) for t in tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que corresponderá a qualquer token único e o colocará entre parênteses para que apenas a palavra correspondida (por exemplo, com dinheiro ) e não a frase correspondida (por exemplo, um homem com dinheiro ) seja produzida. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monied; nervous; dangerous; white; white; white; pious; queer; good;\n",
      "mature; white; Cape; great; wise; wise; butterless; white; fiendish;\n",
      "pale; furious; better; certain; complete; dismasted; younger; brave;\n",
      "brave; brave; brave\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import gutenberg, nps_chat\n",
    "moby = nltk.Text(gutenberg.words('melville-moby_dick.txt'))\n",
    "moby.findall(r\"<a> (<.*>) <man>\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you rule bro; telling you bro; u twizted bro\n"
     ]
    }
   ],
   "source": [
    "chat = nltk.Text (nps_chat.words ())\n",
    "chat.findall(r\"<.*> <.*> <bro>\") #encontra frases de três palavras que terminam com a palavra bro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lol lol lol; lmao lol lol; lol lol lol; la la la la la; la la la; la\n",
      "la la; lovely lol lol love; lol lol lol.; la la la; la la la\n"
     ]
    }
   ],
   "source": [
    "chat.findall(r\"<l.*>{3,}\")#encontra sequências de três ou mais palavras começando com a letra l "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nltk.re_show ( p, s ) que anota a string s para mostrar cada lugar onde o padrão p foi correspondido, e nltk.app.nemo () que fornece uma interface gráfica para explorando expressões regulares. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speed and other activities; water and other liquids; tomb and other\n",
      "landmarks; Statues and other monuments; pearls and other jewels;\n",
      "charts and other items; roads and other features; figures and other\n",
      "objects; military and other areas; demands and other factors;\n",
      "abstracts and other compilations; iron and other metals\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "hobbies_learned = nltk.Text(brown.words(categories=['hobbies', 'learned']))\n",
    "hobbies_learned.findall(r\"<\\w*> <and> <other> <\\w*s>\") #hiperínimos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pesquisa de corpora também apresenta o problema de falsos negativos, ou seja, omitir casos que gostaríamos de incluir. É arriscado concluir que algum fenômeno linguístico não existe em um corpus apenas porque não conseguimos encontrar qualquer instância de um padrão de pesquisa. Talvez não tenhamos pensado com cuidado o suficiente sobre os padrões adequados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Freqüentemente, queremos ir além disso e remover quaisquer afixos, tarefa conhecida como stemming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma outra etapa é garantir que a forma resultante seja uma palavra conhecida em um dicionário, uma tarefa conhecida como lematização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = \"\"\"DENNIS: Listen, strange women lying in ponds distributing swords\n",
    "is no basis for a system of government.  Supreme executive power derives from\n",
    "a mandate from the masses, not from some farcical aquatic ceremony.\"\"\"\n",
    "tokens = word_tokenize(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['denni',\n",
       " ':',\n",
       " 'listen',\n",
       " ',',\n",
       " 'strang',\n",
       " 'women',\n",
       " 'lie',\n",
       " 'in',\n",
       " 'pond',\n",
       " 'distribut',\n",
       " 'sword',\n",
       " 'is',\n",
       " 'no',\n",
       " 'basi',\n",
       " 'for',\n",
       " 'a',\n",
       " 'system',\n",
       " 'of',\n",
       " 'govern',\n",
       " '.',\n",
       " 'suprem',\n",
       " 'execut',\n",
       " 'power',\n",
       " 'deriv',\n",
       " 'from',\n",
       " 'a',\n",
       " 'mandat',\n",
       " 'from',\n",
       " 'the',\n",
       " 'mass',\n",
       " ',',\n",
       " 'not',\n",
       " 'from',\n",
       " 'some',\n",
       " 'farcic',\n",
       " 'aquat',\n",
       " 'ceremoni',\n",
       " '.']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter = nltk.PorterStemmer()\n",
    "lancaster = nltk.LancasterStemmer()\n",
    "[porter.stem(t) for t in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['den',\n",
       " ':',\n",
       " 'list',\n",
       " ',',\n",
       " 'strange',\n",
       " 'wom',\n",
       " 'lying',\n",
       " 'in',\n",
       " 'pond',\n",
       " 'distribut',\n",
       " 'sword',\n",
       " 'is',\n",
       " 'no',\n",
       " 'bas',\n",
       " 'for',\n",
       " 'a',\n",
       " 'system',\n",
       " 'of',\n",
       " 'govern',\n",
       " '.',\n",
       " 'suprem',\n",
       " 'execut',\n",
       " 'pow',\n",
       " 'der',\n",
       " 'from',\n",
       " 'a',\n",
       " 'mand',\n",
       " 'from',\n",
       " 'the',\n",
       " 'mass',\n",
       " ',',\n",
       " 'not',\n",
       " 'from',\n",
       " 'som',\n",
       " 'farc',\n",
       " 'aqu',\n",
       " 'ceremony',\n",
       " '.']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[lancaster.stem(t) for t in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndexedText(object):\n",
    "\n",
    "    def __init__(self, stemmer, text):\n",
    "        self._text = text\n",
    "        self._stemmer = stemmer\n",
    "        self._index = nltk.Index((self._stem(word), i)\n",
    "                                 for (i, word) in enumerate(text))\n",
    "\n",
    "    def concordance(self, word, width=40):\n",
    "        key = self._stem(word)\n",
    "        wc = int(width/4)                # words of context\n",
    "        for i in self._index[key]:\n",
    "            lcontext = ' '.join(self._text[i-wc:i])\n",
    "            rcontext = ' '.join(self._text[i:i+wc])\n",
    "            ldisplay = '{:>{width}}'.format(lcontext[-width:], width=width)\n",
    "            rdisplay = '{:{width}}'.format(rcontext[:width], width=width)\n",
    "            print(ldisplay, rdisplay)\n",
    "\n",
    "    def _stem(self, word):\n",
    "        return self._stemmer.stem(word).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r king ! DENNIS : Listen , strange women lying in ponds distributing swords is no\n",
      " beat a very brave retreat . ROBIN : All lies ! MINSTREL : [ singing ] Bravest of\n",
      "       Nay . Nay . Come . Come . You may lie here . Oh , but you are wounded !   \n",
      "doctors immediately ! No , no , please ! Lie down . [ clap clap ] PIGLET : Well  \n",
      "ere is much danger , for beyond the cave lies the Gorge of Eternal Peril , which \n",
      "   you . Oh ... TIM : To the north there lies a cave -- the cave of Caerbannog --\n",
      "h it and lived ! Bones of full fifty men lie strewn about its lair . So , brave k\n",
      "not stop our fight ' til each one of you lies dead , and the Holy Grail returns t\n"
     ]
    }
   ],
   "source": [
    "grail = nltk.corpus.webtext.words('grail.txt')\n",
    "text = IndexedText(porter, grail)\n",
    "text.concordance('lie')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O lematizador do WordNet remove apenas afixos se a palavra resultante estiver em seu dicionário. Esse processo de verificação adicional torna o lematizador mais lento do que os lematizadores acima. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DENNIS',\n",
       " ':',\n",
       " 'Listen',\n",
       " ',',\n",
       " 'strange',\n",
       " 'woman',\n",
       " 'lying',\n",
       " 'in',\n",
       " 'pond',\n",
       " 'distributing',\n",
       " 'sword',\n",
       " 'is',\n",
       " 'no',\n",
       " 'basis',\n",
       " 'for',\n",
       " 'a',\n",
       " 'system',\n",
       " 'of',\n",
       " 'government',\n",
       " '.',\n",
       " 'Supreme',\n",
       " 'executive',\n",
       " 'power',\n",
       " 'derives',\n",
       " 'from',\n",
       " 'a',\n",
       " 'mandate',\n",
       " 'from',\n",
       " 'the',\n",
       " 'mass',\n",
       " ',',\n",
       " 'not',\n",
       " 'from',\n",
       " 'some',\n",
       " 'farcical',\n",
       " 'aquatic',\n",
       " 'ceremony',\n",
       " '.']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnl = nltk.WordNetLemmatizer()\n",
    "[wnl.lemmatize(t) for t in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = \"\"\"'When I'M a Duchess,' she said to herself, (not in a very hopeful tone\n",
    " though), 'I won't have any pepper in my kitchen AT ALL. Soup does very\n",
    " well without--Maybe it's always pepper that makes people hot-tempered,'...\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'When\",\n",
       " \"I'M\",\n",
       " 'a',\n",
       " \"Duchess,'\",\n",
       " 'she',\n",
       " 'said',\n",
       " 'to',\n",
       " 'herself,',\n",
       " '(not',\n",
       " 'in',\n",
       " 'a',\n",
       " 'very',\n",
       " 'hopeful',\n",
       " 'tone\\n',\n",
       " 'though),',\n",
       " \"'I\",\n",
       " \"won't\",\n",
       " 'have',\n",
       " 'any',\n",
       " 'pepper',\n",
       " 'in',\n",
       " 'my',\n",
       " 'kitchen',\n",
       " 'AT',\n",
       " 'ALL.',\n",
       " 'Soup',\n",
       " 'does',\n",
       " 'very\\n',\n",
       " 'well',\n",
       " 'without--Maybe',\n",
       " \"it's\",\n",
       " 'always',\n",
       " 'pepper',\n",
       " 'that',\n",
       " 'makes',\n",
       " 'people',\n",
       " \"hot-tempered,'...\"]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split(r' ', raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'When\",\n",
       " \"I'M\",\n",
       " 'a',\n",
       " \"Duchess,'\",\n",
       " 'she',\n",
       " 'said',\n",
       " 'to',\n",
       " 'herself,',\n",
       " '(not',\n",
       " 'in',\n",
       " 'a',\n",
       " 'very',\n",
       " 'hopeful',\n",
       " 'tone',\n",
       " 'though),',\n",
       " \"'I\",\n",
       " \"won't\",\n",
       " 'have',\n",
       " 'any',\n",
       " 'pepper',\n",
       " 'in',\n",
       " 'my',\n",
       " 'kitchen',\n",
       " 'AT',\n",
       " 'ALL.',\n",
       " 'Soup',\n",
       " 'does',\n",
       " 'very',\n",
       " 'well',\n",
       " 'without--Maybe',\n",
       " \"it's\",\n",
       " 'always',\n",
       " 'pepper',\n",
       " 'that',\n",
       " 'makes',\n",
       " 'people',\n",
       " \"hot-tempered,'...\"]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split(r'[ \\t\\n]+', raw)#pois isso resulta em tokens que contêm um \\ n \\t ou algo do gênero\n",
    "#corresponde a um ou mais espaços, tabulação ( \\ t ) ou nova linha ( \\ n )."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " lembre-se de prefixar as expressões regulares com a letra r (que significa \"bruto\"), que instrui o interpretador Python a tratar a string literalmente, em vez de processar quaisquer caracteres com barra invertida que ela contenha."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Uma alternativa é usar o fato de que o Python nos fornece uma classe de caracteres \\ w para caracteres de palavras, equivalente a [a-zA-Z0-9_] . ele também define o complemento desta classe \\ W , ou seja, todos os outros do que letras, números ou caracteres de sublinhado podemos usar. \\ W em uma expressão regular simples para dividir a entrada em qualquer coisa diferente do que um caractere de palavra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'When',\n",
       " 'I',\n",
       " 'M',\n",
       " 'a',\n",
       " 'Duchess',\n",
       " 'she',\n",
       " 'said',\n",
       " 'to',\n",
       " 'herself',\n",
       " 'not',\n",
       " 'in',\n",
       " 'a',\n",
       " 'very',\n",
       " 'hopeful',\n",
       " 'tone',\n",
       " 'though',\n",
       " 'I',\n",
       " 'won',\n",
       " 't',\n",
       " 'have',\n",
       " 'any',\n",
       " 'pepper',\n",
       " 'in',\n",
       " 'my',\n",
       " 'kitchen',\n",
       " 'AT',\n",
       " 'ALL',\n",
       " 'Soup',\n",
       " 'does',\n",
       " 'very',\n",
       " 'well',\n",
       " 'without',\n",
       " 'Maybe',\n",
       " 'it',\n",
       " 's',\n",
       " 'always',\n",
       " 'pepper',\n",
       " 'that',\n",
       " 'makes',\n",
       " 'people',\n",
       " 'hot',\n",
       " 'tempered',\n",
       " '']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split(r'\\W+', raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ". A expressão regular « \\ w + | \\ S \\ w * » tentará primeiro corresponder a qualquer sequência de caracteres de palavras. Se nenhuma correspondência for encontrada, ele tentará corresponder a qualquer caractere que não seja de espaço em branco ( \\ S é o complemento de \\ s) seguido por outros caracteres de palavra. Isso significa que a pontuação é agrupada com quaisquer letras seguintes (por exemplo, 's ), mas que as sequências de dois ou mais caracteres de pontuação são separadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'When\",\n",
       " 'I',\n",
       " \"'M\",\n",
       " 'a',\n",
       " 'Duchess',\n",
       " ',',\n",
       " \"'\",\n",
       " 'she',\n",
       " 'said',\n",
       " 'to',\n",
       " 'herself',\n",
       " ',',\n",
       " '(not',\n",
       " 'in',\n",
       " 'a',\n",
       " 'very',\n",
       " 'hopeful',\n",
       " 'tone',\n",
       " 'though',\n",
       " ')',\n",
       " ',',\n",
       " \"'I\",\n",
       " 'won',\n",
       " \"'t\",\n",
       " 'have',\n",
       " 'any',\n",
       " 'pepper',\n",
       " 'in',\n",
       " 'my',\n",
       " 'kitchen',\n",
       " 'AT',\n",
       " 'ALL',\n",
       " '.',\n",
       " 'Soup',\n",
       " 'does',\n",
       " 'very',\n",
       " 'well',\n",
       " 'without',\n",
       " '-',\n",
       " '-Maybe',\n",
       " 'it',\n",
       " \"'s\",\n",
       " 'always',\n",
       " 'pepper',\n",
       " 'that',\n",
       " 'makes',\n",
       " 'people',\n",
       " 'hot',\n",
       " '-tempered',\n",
       " ',',\n",
       " \"'\",\n",
       " '.',\n",
       " '.',\n",
       " '.']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'\\w+|\\S\\w*', raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'When\",\n",
       " 'I',\n",
       " \"'M\",\n",
       " 'a',\n",
       " 'Duchess',\n",
       " ',',\n",
       " \"'\",\n",
       " 'she',\n",
       " 'said',\n",
       " 'to',\n",
       " 'herself',\n",
       " ',',\n",
       " '(not',\n",
       " 'in',\n",
       " 'a',\n",
       " 'very',\n",
       " 'hopeful',\n",
       " 'tone',\n",
       " 'though',\n",
       " ')',\n",
       " ',',\n",
       " \"'I\",\n",
       " 'won',\n",
       " \"'t\",\n",
       " 'have',\n",
       " 'any',\n",
       " 'pepper',\n",
       " 'in',\n",
       " 'my',\n",
       " 'kitchen',\n",
       " 'AT',\n",
       " 'ALL',\n",
       " '.',\n",
       " 'Soup',\n",
       " 'does',\n",
       " 'very',\n",
       " 'well',\n",
       " 'without',\n",
       " '-',\n",
       " '-Maybe',\n",
       " 'it',\n",
       " \"'s\",\n",
       " 'always',\n",
       " 'pepper',\n",
       " 'that',\n",
       " 'makes',\n",
       " 'people',\n",
       " 'hot',\n",
       " '-tempered',\n",
       " ',',\n",
       " \"'\",\n",
       " '.',\n",
       " '.',\n",
       " '.']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'\\w+|\\S\\w*', raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função nltk.regexp_tokenize () é semelhante a re.findall () (já que estamos usando para tokenização). No entanto, nltk.regexp_tokenize () é mais eficiente para esta tarefa e evita a necessidade de tratamento especial para parênteses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['That', 'U.S.A.', 'poster-print', 'costs', '$12.40', '...']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'That U.S.A. poster-print costs $12.40...'\n",
    "pattern = r'''(?x)     # set flag to allow verbose regexps\n",
    "     (?:[A-Z]\\.)+       # abbreviations, e.g. U.S.A.\n",
    "   | \\w+(?:-\\w+)*       # words with optional internal hyphens\n",
    "   | \\$?\\d+(?:\\.\\d+)?%? # currency and percentages, e.g. $12.40, 82%\n",
    "   | \\.\\.\\.             # ellipsis\n",
    "   | [][.,;\"'?():-_`]   # these are separate tokens; includes ], [\n",
    " '''\n",
    "nltk.regexp_tokenize(text, pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao usar o sinalizador detalhado, você não pode mais usar '' para corresponder a um caractere de espaço; use \\ s em vez disso. A função regexp_tokenize () tem um parâmetro opcional de lacunas . Quando definida como True , a expressão regular especifica as lacunas entre os tokens, como com re.split () "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos avaliar um tokenizer comparando os tokens resultantes com uma lista de palavras e relatando todos os tokens que não aparecem na lista de palavras, usando\n",
    "set(tokens).difference(wordlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manipular textos no nível de palavras individuais freqüentemente pressupõe a capacidade de dividir um texto em sentenças individuais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.250994070456922"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len (nltk.corpus.brown.words ()) / len (nltk.corpus.brown.sents ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"Nonsense!\"',\n",
       " 'said Gregory, who was very rational when anyone else\\nattempted paradox.',\n",
       " '\"Why do all the clerks and navvies in the\\nrailway trains look so sad and tired, so very sad and tired?',\n",
       " 'I will\\ntell you.',\n",
       " 'It is because they know that the train is going right.',\n",
       " 'It\\nis because they know that whatever place they have taken a ticket\\nfor that place they will reach.',\n",
       " 'It is because after they have\\npassed Sloane Square they know that the next station must be\\nVictoria, and nothing but Victoria.',\n",
       " 'Oh, their wild rapture!',\n",
       " 'oh,\\ntheir eyes like stars and their souls again in Eden, if the next\\nstation were unaccountably Baker Street!\"',\n",
       " '\"It is you who are unpoetical,\" replied the poet Syme.']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = nltk.corpus.gutenberg.raw('chesterton-thursday.txt')\n",
    "sents = nltk.sent_tokenize(text)\n",
    "sents[79:89]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"doyouseethekittyseethedoggydoyoulikethekittylikethedoggy\"\n",
    "seg1 = \"0000000000000001000000000010000000000000000100000000000\"\n",
    "seg2 = \"0100100100100001001001000010100100010010000100010010000\"\n",
    "def segment(text, segs):\n",
    "    words = []\n",
    "    last = 0\n",
    "    for i in range(len(segs)):\n",
    "        if segs[i] == '1':\n",
    "            words.append(text[last:i+1])\n",
    "            last = i+1\n",
    "    words.append(text[last:])\n",
    "    return words\n",
    "segment(text, seg1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['do',\n",
       " 'you',\n",
       " 'see',\n",
       " 'the',\n",
       " 'kitty',\n",
       " 'see',\n",
       " 'the',\n",
       " 'doggy',\n",
       " 'do',\n",
       " 'you',\n",
       " 'like',\n",
       " 'the',\n",
       " 'kitty',\n",
       " 'like',\n",
       " 'the',\n",
       " 'doggy']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment(text, seg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, a tarefa de segmentação se torna um problema de pesquisa: encontre a sequência de bits que faz com que a sequência de texto seja segmentada corretamente em palavras. Presumimos que o aluno está adquirindo palavras e armazenando-as em um léxico interno. Dado um léxico adequado, é possível reconstruir o texto de origem como uma sequência de itens lexicais. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cálculo da função objetivo: Dada uma segmentação hipotética do texto de origem (à esquerda), deduza um léxico e uma tabela de derivação que permita que o texto de origem seja reconstruído e, em seguida, some o número de caracteres usados ​​por cada item léxico (incluindo um marcador de limite) e o número de itens lexicais usados ​​por cada derivação, para servir como uma pontuação da qualidade da segmentação; valores menores da pontuação indicam uma melhor segmentação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['doyou',\n",
       " 'see',\n",
       " 'thekitt',\n",
       " 'y',\n",
       " 'see',\n",
       " 'thedogg',\n",
       " 'y',\n",
       " 'doyou',\n",
       " 'like',\n",
       " 'thekitt',\n",
       " 'y',\n",
       " 'like',\n",
       " 'thedogg',\n",
       " 'y']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate(text, segs):\n",
    "    words = segment(text, segs)\n",
    "    text_size = len(words)\n",
    "    lexicon_size = sum(len(word) + 1 for word in set(words))\n",
    "    return text_size + lexicon_size\n",
    "seg3 = \"0000100100000011001000000110000100010000001100010000001\"\n",
    "segment(text, seg3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(text, seg3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(text, seg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(text, seg1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "def flip(segs, pos):\n",
    "    return segs[:pos] + str(1-int(segs[pos])) + segs[pos+1:]\n",
    "\n",
    "def flip_n(segs, n):\n",
    "    for i in range(n):\n",
    "        segs = flip(segs, randint(0, len(segs)-1))\n",
    "    return segs\n",
    "\n",
    "def anneal(text, segs, iterations, cooling_rate):\n",
    "    temperature = float(len(segs))\n",
    "    while temperature > 0.5:\n",
    "        best_segs, best = segs, evaluate(text, segs)\n",
    "        for i in range(iterations):\n",
    "            guess = flip_n(segs, round(temperature))\n",
    "            score = evaluate(text, guess)\n",
    "            if score < best:\n",
    "                best, best_segs = score, guess\n",
    "        score, segs = best, best_segs\n",
    "        temperature = temperature / cooling_rate\n",
    "        print(evaluate(text, segs), segment(text, segs))\n",
    "    print()\n",
    "    return segs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 ['doyouseethekitty', 'seethedoggydoyo', 'ulikethekittylike', 'thedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggydoyo', 'ulikethekittylike', 'thedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggydoyo', 'ulikethekittylike', 'thedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggydoyo', 'ulikethekittylike', 'thedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggydoyo', 'ulikethekittylike', 'thedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggydoyo', 'ulikethekittylike', 'thedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggydoyo', 'ulikethekittylike', 'thedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggydoyo', 'ulikethekittylike', 'thedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggydoyo', 'ulikethekittylike', 'thedoggy']\n",
      "62 ['doyou', 'seethekittyseethe', 'doggy', 'doyou', 'likethekittyli', 'keth', 'e', 'doggy', '']\n",
      "62 ['doyou', 'seethekittyseethe', 'doggy', 'doyou', 'likethekittyli', 'keth', 'e', 'doggy', '']\n",
      "62 ['doyou', 'seethekittyseethe', 'doggy', 'doyou', 'likethekittyli', 'keth', 'e', 'doggy', '']\n",
      "60 ['doyou', 'seethekittysee', 'the', 'doggy', 'doyou', 'liketheki', 'ttylikethe', 'doggy']\n",
      "56 ['doyou', 'seethekittysee', 'the', 'doggy', 'doyou', 'likethe', 'ki', 'tty', 'likethe', 'doggy']\n",
      "51 ['doyou', 'seethe', 'kitty', 'seethe', 'dog', 'gy', 'doyou', 'likethe', 'kitty', 'likethe', 'doggy']\n",
      "48 ['doyou', 'seethe', 'kitty', 'seethe', 'dog', 'gy', 'doyou', 'likethe', 'kitty', 'likethe', 'dog', 'gy', '']\n",
      "43 ['doyou', 'seethe', 'kitty', 'seethe', 'doggy', 'doyou', 'likethe', 'kitty', 'likethe', 'doggy']\n",
      "43 ['doyou', 'seethe', 'kitty', 'seethe', 'doggy', 'doyou', 'likethe', 'kitty', 'likethe', 'doggy']\n",
      "43 ['doyou', 'seethe', 'kitty', 'seethe', 'doggy', 'doyou', 'likethe', 'kitty', 'likethe', 'doggy']\n",
      "43 ['doyou', 'seethe', 'kitty', 'seethe', 'doggy', 'doyou', 'likethe', 'kitty', 'likethe', 'doggy']\n",
      "43 ['doyou', 'seethe', 'kitty', 'seethe', 'doggy', 'doyou', 'likethe', 'kitty', 'likethe', 'doggy']\n",
      "43 ['doyou', 'seethe', 'kitty', 'seethe', 'doggy', 'doyou', 'likethe', 'kitty', 'likethe', 'doggy']\n",
      "43 ['doyou', 'seethe', 'kitty', 'seethe', 'doggy', 'doyou', 'likethe', 'kitty', 'likethe', 'doggy']\n",
      "43 ['doyou', 'seethe', 'kitty', 'seethe', 'doggy', 'doyou', 'likethe', 'kitty', 'likethe', 'doggy']\n",
      "43 ['doyou', 'seethe', 'kitty', 'seethe', 'doggy', 'doyou', 'likethe', 'kitty', 'likethe', 'doggy']\n",
      "43 ['doyou', 'seethe', 'kitty', 'seethe', 'doggy', 'doyou', 'likethe', 'kitty', 'likethe', 'doggy']\n",
      "43 ['doyou', 'seethe', 'kitty', 'seethe', 'doggy', 'doyou', 'likethe', 'kitty', 'likethe', 'doggy']\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'00001000001000010000010000100001000000100001000000100000000'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"doyouseethekittyseethedoggydoyoulikethekittylikethedoggy\" \n",
    "seg1 = \"00000000000000010000000000000010000000000000000100000000000\" \n",
    "anneal (text, seg1, 5000, 1.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat -> 3; dog -> 4; snake -> 1; "
     ]
    }
   ],
   "source": [
    "fdist = nltk.FreqDist(['dog', 'cat', 'dog', 'cat', 'dog', 'snake', 'dog', 'cat'])\n",
    "for word in sorted(fdist):\n",
    "    print(word, '->', fdist[word], end='; ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat->3; dog->4; snake->1; "
     ]
    }
   ],
   "source": [
    "for word in sorted(fdist):\n",
    "    print('{}->{};'.format(word, fdist[word]), end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lee quer um sanduíche'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{} quer um {}' .format ( 'Lee' , 'sanduíche' , 'para o almoço' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Portanto, {: 6} especifica que queremos uma string preenchida até a largura 6. É justificada à direita por padrão para números[1] , mas podemos preceder o especificador de largura com uma opção de alinhamento '<' para tornar os números justificados à esquerda [2]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    41'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{:6}'.format(41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'41    '"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{:<6}' .format(41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.1416'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "'{:.4f}'.format(math.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tabulate(cfdist, words, categories):\n",
    "    print('{:16}'.format('Category'), end=' ')                    # column headings\n",
    "    for word in words:\n",
    "        print('{:>6}'.format(word), end=' ')\n",
    "    print()\n",
    "    for category in categories:\n",
    "        print('{:16}'.format(category), end=' ')                  # row heading\n",
    "        for word in words:                                        # for each word\n",
    "            print('{:6}'.format(cfdist[category][word]), end=' ') # print table cell\n",
    "        print()                                                   # end the row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category            can  could    may  might   must   will \n",
      "news                 93     86     66     38     50    389 \n",
      "religion             82     59     78     12     54     71 \n",
      "hobbies             268     58    131     22     83    264 \n",
      "science_fiction      16     49      4     12      8     16 \n",
      "romance              74    193     11     51     45     43 \n",
      "humor                16     30      8      8      9     13 \n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "cfd = nltk.ConditionalFreqDist(\n",
    "           (genre, word)\n",
    "           for genre in brown.categories()\n",
    "           for word in brown.words(categories=genre))\n",
    "genres = ['news', 'religion', 'hobbies', 'science_fiction', 'romance', 'humor']\n",
    "modals = ['can', 'could', 'may', 'might', 'must', 'will']\n",
    "tabulate(cfd, modals, genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Monty Python   '"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{:{width}}'.format('Monty Python', width=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = open('output.txt', 'w')\n",
    "words = set(nltk.corpus.genesis.words('english-kjv.txt'))\n",
    "for word in sorted(words):\n",
    "     print(word, file=output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(len(words)), file=output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After (5), all (3), is (2), said (4), and (3), done (4), , (1), more (4), is (2), said (4), than (4), done (4), . (1), "
     ]
    }
   ],
   "source": [
    "saying = ['After', 'all', 'is', 'said', 'and', 'done', ',',\n",
    "           'more', 'is', 'said', 'than', 'done', '.']\n",
    "for word in saying:\n",
    "     print(word, '(' + str(len(word)) + '),', end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 5 all 3 is 2 said 4 and 3 done 4 , 1 more 4 is 2 said 4 than 4\n",
      "done 4 . 1\n"
     ]
    }
   ],
   "source": [
    "from textwrap import fill\n",
    "pieces = [\"{} {}\".format(word, len(word)) for word in saying]\n",
    "output = ' '.join(pieces)\n",
    "wrapped = fill(output)\n",
    "print(wrapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
